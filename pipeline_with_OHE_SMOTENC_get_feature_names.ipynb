{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Feature Names out of a Pipeline\n",
    "\n",
    "This was an excercice to get the feature names out of a pipeline when one-hot-encoding (OHE) is performed in it. Such a procedure can be important if you want to analyse feature importance after having modelled. - To add additional complexity I applied oversampling with SMOTENC in a late step of the pipeline. For this the indices of the one-hot-encoded categorical columns have to be passed.\n",
    "\n",
    "It seems that there are three possible solutions to this:\n",
    "1. OHE outside of the pipeline and you have direct access to the feature names (the easiest way and quite ok, I think)\n",
    "2. OHE inside the pipeline and you infere the feature names (pragmatic but you better make sure you got it right)\n",
    "3. OHE inside the pipeline and you get the feature names out of it (or of a cloned pipeline ... as was necessary here)\n",
    "\n",
    "I worked on solution 3 in this notebook. That was kind of a hassle because the sklearn ColumnTransformer (or FeatureUnion) object only returns the feature names if all transformers within it provide the method get_feature_names(). Unfortunately some like StandardScaler do not (yet). The work-around was to build a second pipeline just to get the feature names. There I substituted the StandardScaler with a custom 'PasstroughTransformer' that passes the data unchanged but has the necessary get_feature_names() method (see [here](https://stackoverflow.com/questions/53382322/adding-get-feature-names-to-columntransformer-pipeline) for background info).\n",
    "\n",
    "_NOTE: the original data is not provided for this notebook_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV, \\\n",
    "    cross_val_score, StratifiedKFold, validation_curve, learning_curve\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import make_scorer, classification_report, confusion_matrix, fbeta_score\n",
    "\n",
    "import custom_transformers as transform\n",
    "import cleaning_functions as clean\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set; sns.set_style('whitegrid')\n",
    "%matplotlib inline  \n",
    "\n",
    "# display of all columns in df - check if pd option below isn't better\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = pd.read_csv('Financial Distress.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3670 entries, 0 to 3669\n",
      "Columns: 127 entries, Company to x124\n",
      "dtypes: float64(114), int64(13)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "XX.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Time</th>\n",
       "      <th>Financial Distress</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "      <th>x33</th>\n",
       "      <th>x34</th>\n",
       "      <th>x35</th>\n",
       "      <th>x36</th>\n",
       "      <th>x37</th>\n",
       "      <th>x38</th>\n",
       "      <th>x39</th>\n",
       "      <th>x40</th>\n",
       "      <th>x41</th>\n",
       "      <th>x42</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>x50</th>\n",
       "      <th>x51</th>\n",
       "      <th>x52</th>\n",
       "      <th>x53</th>\n",
       "      <th>x54</th>\n",
       "      <th>x55</th>\n",
       "      <th>x56</th>\n",
       "      <th>x57</th>\n",
       "      <th>x58</th>\n",
       "      <th>x59</th>\n",
       "      <th>x60</th>\n",
       "      <th>x61</th>\n",
       "      <th>x62</th>\n",
       "      <th>x63</th>\n",
       "      <th>x64</th>\n",
       "      <th>x65</th>\n",
       "      <th>x66</th>\n",
       "      <th>x67</th>\n",
       "      <th>x68</th>\n",
       "      <th>x69</th>\n",
       "      <th>x70</th>\n",
       "      <th>x71</th>\n",
       "      <th>x72</th>\n",
       "      <th>x73</th>\n",
       "      <th>x74</th>\n",
       "      <th>x75</th>\n",
       "      <th>x76</th>\n",
       "      <th>x77</th>\n",
       "      <th>x78</th>\n",
       "      <th>x79</th>\n",
       "      <th>x80</th>\n",
       "      <th>x81</th>\n",
       "      <th>x82</th>\n",
       "      <th>x83</th>\n",
       "      <th>x84</th>\n",
       "      <th>x85</th>\n",
       "      <th>x86</th>\n",
       "      <th>x87</th>\n",
       "      <th>x88</th>\n",
       "      <th>x89</th>\n",
       "      <th>x90</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>x100</th>\n",
       "      <th>x101</th>\n",
       "      <th>x102</th>\n",
       "      <th>x103</th>\n",
       "      <th>x104</th>\n",
       "      <th>x105</th>\n",
       "      <th>x106</th>\n",
       "      <th>x107</th>\n",
       "      <th>x108</th>\n",
       "      <th>x109</th>\n",
       "      <th>x110</th>\n",
       "      <th>x111</th>\n",
       "      <th>x112</th>\n",
       "      <th>x113</th>\n",
       "      <th>x114</th>\n",
       "      <th>x115</th>\n",
       "      <th>x116</th>\n",
       "      <th>x117</th>\n",
       "      <th>x118</th>\n",
       "      <th>x119</th>\n",
       "      <th>x120</th>\n",
       "      <th>x121</th>\n",
       "      <th>x122</th>\n",
       "      <th>x123</th>\n",
       "      <th>x124</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>1.281</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.87454</td>\n",
       "      <td>1.2164</td>\n",
       "      <td>0.06094</td>\n",
       "      <td>0.18827</td>\n",
       "      <td>0.52510</td>\n",
       "      <td>0.018854</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>0.85822</td>\n",
       "      <td>2.00580</td>\n",
       "      <td>0.12546</td>\n",
       "      <td>6.9706</td>\n",
       "      <td>4.6512</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>2.1984</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.024978</td>\n",
       "      <td>0.027264</td>\n",
       "      <td>1.4173</td>\n",
       "      <td>9.5554</td>\n",
       "      <td>0.148720</td>\n",
       "      <td>0.66995</td>\n",
       "      <td>214.760</td>\n",
       "      <td>12.641</td>\n",
       "      <td>6.4607</td>\n",
       "      <td>0.043835</td>\n",
       "      <td>0.20459</td>\n",
       "      <td>0.35179</td>\n",
       "      <td>8.3161</td>\n",
       "      <td>0.28922</td>\n",
       "      <td>0.76606</td>\n",
       "      <td>2.5825</td>\n",
       "      <td>77.400</td>\n",
       "      <td>0.026722</td>\n",
       "      <td>1.63070</td>\n",
       "      <td>0.015016</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>9.6951</td>\n",
       "      <td>-0.73622</td>\n",
       "      <td>0.98559</td>\n",
       "      <td>0.180160</td>\n",
       "      <td>1.5006</td>\n",
       "      <td>0.026224</td>\n",
       "      <td>7.0513</td>\n",
       "      <td>1174.9</td>\n",
       "      <td>5.3399</td>\n",
       "      <td>0.85128</td>\n",
       "      <td>12.837</td>\n",
       "      <td>0.061737</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>209.87</td>\n",
       "      <td>-0.58255</td>\n",
       "      <td>0.47101</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22009</td>\n",
       "      <td>0.130760</td>\n",
       "      <td>0.149520</td>\n",
       "      <td>0.195180</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>1224.50</td>\n",
       "      <td>1.04220</td>\n",
       "      <td>4.8920</td>\n",
       "      <td>6.72910</td>\n",
       "      <td>0.53860</td>\n",
       "      <td>104.410</td>\n",
       "      <td>0.49844</td>\n",
       "      <td>2.32240</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.14653</td>\n",
       "      <td>1.0214</td>\n",
       "      <td>24.402</td>\n",
       "      <td>-47.071</td>\n",
       "      <td>129</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>-0.4623</td>\n",
       "      <td>391.0</td>\n",
       "      <td>2870000.0</td>\n",
       "      <td>8.990000e+09</td>\n",
       "      <td>31</td>\n",
       "      <td>3.140000e+10</td>\n",
       "      <td>9.980000e-09</td>\n",
       "      <td>25.75</td>\n",
       "      <td>0.19693</td>\n",
       "      <td>74.25</td>\n",
       "      <td>38.44</td>\n",
       "      <td>15.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.1241</td>\n",
       "      <td>15.381</td>\n",
       "      <td>3.2702</td>\n",
       "      <td>17.872</td>\n",
       "      <td>34.692</td>\n",
       "      <td>30.087</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7991.4</td>\n",
       "      <td>364.9500</td>\n",
       "      <td>15.8</td>\n",
       "      <td>61.476</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.437</td>\n",
       "      <td>27.07</td>\n",
       "      <td>26.102</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.060390</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.455970</td>\n",
       "      <td>1.270</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.82067</td>\n",
       "      <td>1.0049</td>\n",
       "      <td>-0.01408</td>\n",
       "      <td>0.18104</td>\n",
       "      <td>0.62288</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.035991</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.85152</td>\n",
       "      <td>-0.48644</td>\n",
       "      <td>0.17933</td>\n",
       "      <td>4.5764</td>\n",
       "      <td>3.7521</td>\n",
       "      <td>-0.014011</td>\n",
       "      <td>2.4575</td>\n",
       "      <td>0.027558</td>\n",
       "      <td>0.028804</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>1.1801</td>\n",
       "      <td>7.2952</td>\n",
       "      <td>0.056026</td>\n",
       "      <td>0.67048</td>\n",
       "      <td>38.242</td>\n",
       "      <td>12.877</td>\n",
       "      <td>5.5506</td>\n",
       "      <td>0.265480</td>\n",
       "      <td>0.15019</td>\n",
       "      <td>0.41763</td>\n",
       "      <td>9.5276</td>\n",
       "      <td>0.41561</td>\n",
       "      <td>0.81699</td>\n",
       "      <td>2.6033</td>\n",
       "      <td>95.947</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.83754</td>\n",
       "      <td>0.027425</td>\n",
       "      <td>0.045434</td>\n",
       "      <td>0.13774</td>\n",
       "      <td>5.6035</td>\n",
       "      <td>-0.64385</td>\n",
       "      <td>1.30190</td>\n",
       "      <td>0.046857</td>\n",
       "      <td>1.0095</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>4.6022</td>\n",
       "      <td>1062.5</td>\n",
       "      <td>3.7389</td>\n",
       "      <td>0.94397</td>\n",
       "      <td>12.881</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>0.056298</td>\n",
       "      <td>250.14</td>\n",
       "      <td>-0.47477</td>\n",
       "      <td>0.38599</td>\n",
       "      <td>0.36933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.042671</td>\n",
       "      <td>-0.051995</td>\n",
       "      <td>-0.063643</td>\n",
       "      <td>-0.042465</td>\n",
       "      <td>-252.83</td>\n",
       "      <td>-0.23795</td>\n",
       "      <td>-2.0869</td>\n",
       "      <td>-0.98939</td>\n",
       "      <td>-0.23212</td>\n",
       "      <td>-10.857</td>\n",
       "      <td>-0.18801</td>\n",
       "      <td>0.90531</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.40390</td>\n",
       "      <td>1.8484</td>\n",
       "      <td>25.588</td>\n",
       "      <td>88.667</td>\n",
       "      <td>229</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>3.5409</td>\n",
       "      <td>126.0</td>\n",
       "      <td>371000.0</td>\n",
       "      <td>5.410000e+08</td>\n",
       "      <td>27</td>\n",
       "      <td>7.240000e+08</td>\n",
       "      <td>5.320000e-08</td>\n",
       "      <td>26.78</td>\n",
       "      <td>0.22990</td>\n",
       "      <td>73.22</td>\n",
       "      <td>42.86</td>\n",
       "      <td>15.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.4166</td>\n",
       "      <td>7.105</td>\n",
       "      <td>14.3210</td>\n",
       "      <td>18.770</td>\n",
       "      <td>124.760</td>\n",
       "      <td>26.124</td>\n",
       "      <td>11.8</td>\n",
       "      <td>8322.8</td>\n",
       "      <td>0.1896</td>\n",
       "      <td>15.6</td>\n",
       "      <td>24.579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>107.090</td>\n",
       "      <td>31.31</td>\n",
       "      <td>30.194</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company  Time  Financial Distress     x1        x2       x3      x4  \\\n",
       "0        1     1            0.010636  1.281  0.022934  0.87454  1.2164   \n",
       "1        1     2           -0.455970  1.270  0.006454  0.82067  1.0049   \n",
       "\n",
       "        x5       x6       x7        x8        x9       x10      x11      x12  \\\n",
       "0  0.06094  0.18827  0.52510  0.018854  0.182790  0.006449  0.85822  2.00580   \n",
       "1 -0.01408  0.18104  0.62288  0.006423  0.035991  0.001795  0.85152 -0.48644   \n",
       "\n",
       "       x13     x14     x15       x16     x17       x18       x19       x20  \\\n",
       "0  0.12546  6.9706  4.6512  0.050100  2.1984  0.018265  0.024978  0.027264   \n",
       "1  0.17933  4.5764  3.7521 -0.014011  2.4575  0.027558  0.028804  0.041102   \n",
       "\n",
       "      x21     x22       x23      x24      x25     x26     x27       x28  \\\n",
       "0  1.4173  9.5554  0.148720  0.66995  214.760  12.641  6.4607  0.043835   \n",
       "1  1.1801  7.2952  0.056026  0.67048   38.242  12.877  5.5506  0.265480   \n",
       "\n",
       "       x29      x30     x31      x32      x33     x34     x35       x36  \\\n",
       "0  0.20459  0.35179  8.3161  0.28922  0.76606  2.5825  77.400  0.026722   \n",
       "1  0.15019  0.41763  9.5276  0.41561  0.81699  2.6033  95.947  0.007580   \n",
       "\n",
       "       x37       x38       x39      x40     x41      x42      x43       x44  \\\n",
       "0  1.63070  0.015016  0.005478  0.12730  9.6951 -0.73622  0.98559  0.180160   \n",
       "1  0.83754  0.027425  0.045434  0.13774  5.6035 -0.64385  1.30190  0.046857   \n",
       "\n",
       "      x45       x46     x47     x48     x49      x50     x51       x52  \\\n",
       "0  1.5006  0.026224  7.0513  1174.9  5.3399  0.85128  12.837  0.061737   \n",
       "1  1.0095  0.007864  4.6022  1062.5  3.7389  0.94397  12.881 -0.000565   \n",
       "\n",
       "        x53     x54      x55      x56      x57  x58  x59      x60       x61  \\\n",
       "0  0.180900  209.87 -0.58255  0.47101  0.10990  0.0  0.0  0.22009  0.130760   \n",
       "1  0.056298  250.14 -0.47477  0.38599  0.36933  0.0  0.0  0.00000 -0.042671   \n",
       "\n",
       "        x62       x63       x64      x65      x66     x67      x68      x69  \\\n",
       "0  0.149520  0.195180  0.107500  1224.50  1.04220  4.8920  6.72910  0.53860   \n",
       "1 -0.051995 -0.063643 -0.042465  -252.83 -0.23795 -2.0869 -0.98939 -0.23212   \n",
       "\n",
       "       x70      x71      x72    x73      x74     x75     x76     x77  x78  \\\n",
       "0  104.410  0.49844  2.32240  300.0  0.14653  1.0214  24.402 -47.071  129   \n",
       "1  -10.857 -0.18801  0.90531  100.0  0.40390  1.8484  25.588  88.667  229   \n",
       "\n",
       "      x79     x80    x81        x82           x83  x84           x85  \\\n",
       "0  1200.0 -0.4623  391.0  2870000.0  8.990000e+09   31  3.140000e+10   \n",
       "1  1964.0  3.5409  126.0   371000.0  5.410000e+08   27  7.240000e+08   \n",
       "\n",
       "            x86    x87      x88    x89    x90    x91  x92  x93    x94  x95  \\\n",
       "0  9.980000e-09  25.75  0.19693  74.25  38.44  15.93  0.0  0.0  74.25    1   \n",
       "1  5.320000e-08  26.78  0.22990  73.22  42.86  15.94  0.0  0.0  73.22    1   \n",
       "\n",
       "   x96  x97  x98  x99  x100  x101    x102    x103     x104    x105     x106  \\\n",
       "0    2    0    5    0     0   0.8  7.1241  15.381   3.2702  17.872   34.692   \n",
       "1    2    0    5    0     0   0.6  7.4166   7.105  14.3210  18.770  124.760   \n",
       "\n",
       "     x107  x108    x109      x110  x111    x112  x113  x114     x115   x116  \\\n",
       "0  30.087  12.8  7991.4  364.9500  15.8  61.476   4.0  36.0   85.437  27.07   \n",
       "1  26.124  11.8  8322.8    0.1896  15.6  24.579   0.0  36.0  107.090  31.31   \n",
       "\n",
       "     x117  x118  x119  x120  x121      x122  x123  x124  \n",
       "0  26.102  16.0  16.0   0.2    22  0.060390    30    49  \n",
       "1  30.194  17.0  16.0   0.4    22  0.010636    31    50  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there's no missing data in the set\n",
    "assert XX.isnull().sum().sum() == 0, \"NaN present\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Xy(df):\n",
    "    \"\"\"Seprate target variable from features.\"\"\"\n",
    "\n",
    "    X = df.copy()\n",
    "    y = XX['Financial Distress']\n",
    "    X = X.drop(['Financial Distress'], axis=1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3670, 126)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call function an check results\n",
    "X, y = create_Xy(XX)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 3535],\n",
       "       [   1,  135]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare target feature\n",
    "y = np.array([0 if i > -0.50 else 1 for i in y])\n",
    "\n",
    "# check result\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "display(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x121 , number of unique values (categories):  37\n",
      "x99 , number of unique values (categories):  2\n",
      "\n",
      "Total number of one-hot-encoded cat features:  39\n"
     ]
    }
   ],
   "source": [
    "\"\"\"define numerical and categorical features\"\"\"\n",
    "\n",
    "cat_features = ['x121', 'x99']  # orig: x95, x97, x99, x100, x121\n",
    "\n",
    "X = X.astype(float)  # Column types are defaulted to floats\n",
    "X[cat_features] = X[cat_features].astype('category') # categorical are set to cat\n",
    "\n",
    "num_features = list(X.columns)\n",
    "for feature in cat_features:\n",
    "    num_features.remove(feature)\n",
    "\n",
    "assert (len(num_features) + len(cat_features)) == X.shape[1] # safety check\n",
    "\n",
    "\n",
    "# define number of one-hot-encoded cat features for SMOTENC sampler (and print results)\n",
    "number_cat = 0\n",
    "for feature in cat_features:\n",
    "    values = X[feature].nunique()\n",
    "    print(feature, \", number of unique values (categories): \", values)\n",
    "    number_cat += values\n",
    "print(\"\\nTotal number of one-hot-encoded cat features: \", number_cat)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We will need `cat_features` and `num_features` to select the respective columns in the ColumnTransformer in the Pipeline. the total number of OHE features is necessary that we can pass the correct cat_indices to the SMOTENC sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2569, 126)\n",
      "(1101, 126)\n",
      "(2569,)\n",
      "(1101,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"split data into train and test\"\"\"\n",
    "\n",
    "indices = np.arange(y.shape[0])\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = \\\n",
    "    train_test_split(X, y, indices, stratify=y, test_size=0.3,random_state=42)\n",
    "\n",
    "# check results\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"assemble pipeline (define function)\"\"\"\n",
    "\n",
    "def build_pipe(X_train, y_train, clf, sampler):\n",
    "    \"\"\"Build a pipeline for preprocessing (including oversampling)\n",
    "    and classification.\n",
    "    \n",
    "    ARGUMENTS:\n",
    "        X_train: training features (df or array)\n",
    "        y_train: training labels (df or array)\n",
    "        clf: classifier (sk-learn model object)\n",
    "        sampler: sampler (imblearn sampling class)\n",
    "        \n",
    "    RETURNS:\n",
    "        full_pipe: pipeline object\n",
    "    \"\"\"\n",
    " \n",
    "    preprocessor = ColumnTransformer([\n",
    "            ('ohe', OneHotEncoder(), cat_features),\n",
    "            ('scaling', StandardScaler(), num_features),\n",
    "            ])\n",
    "    \n",
    "    full_pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('sample', sampler),\n",
    "        ('clf', clf)])\n",
    "    \n",
    "    return preprocessor, full_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"initialize  classifier and SMOTENC sampler, build pipeline\"\"\" \n",
    "\n",
    "rg = LogisticRegression(class_weight = { 0:1, 1:1 }, random_state = 42, solver = 'saga',\n",
    "                        max_iter=100, n_jobs=-1, intercept_scaling=1, C=0.02, penalty='l1')\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "sampler = SMOTENC(categorical_features=list(range(0,number_cat)), n_jobs=-1)\n",
    "\n",
    "preprocessor, full_pipe = build_pipe(X_train, y_train, gbc, sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pipe(X_train, y_train, pipe, scorer, cv=StratifiedKFold(3)):\n",
    "    \"\"\"Fit training data to a pipeline with GridSearchCV\n",
    "    for best parameter tuning.\n",
    "    \n",
    "    ARGUMENTS:\n",
    "        X_train: training features (df or array)\n",
    "        y_train: training labels (df or array)\n",
    "        pipe: pipeline (sk-learn pipeline object)\n",
    "        scorer: evaluation metric for validation\n",
    "        cv: type of CV, default is StratifiedKFold(3)\n",
    "        \n",
    "    RETURNS:\n",
    "        grid: grid search object\n",
    "        grid_results: dict with grid search results\n",
    "    \"\"\"\n",
    "    parameters = {'clf__learning_rate': [0.05], \n",
    "#                   'clf__class_weight':   [{ 0:1, 1:11 }, { 0:1, 1:8 }]\n",
    "                 }\n",
    "\n",
    "    cv = GridSearchCV(pipe, param_grid=parameters, scoring=scorer, n_jobs= -1, \n",
    "                      cv=cv, error_score='raise', return_train_score=False, verbose=1)\n",
    "\n",
    "    grid = cv.fit(X_train, y_train) \n",
    "    grid_results = grid.cv_results_\n",
    "\n",
    "    return grid, grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   16.3s finished\n",
      "C:\\Users\\r2d4\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# call the function and evaluate on fbeta score\n",
    "\n",
    "scorer = make_scorer(fbeta_score, beta=4)\n",
    "cv = 3\n",
    "\n",
    "grid, grid_results = fit_pipe(X_train, y_train, full_pipe, scorer, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grid.best_estimator_.named_steps['clf'].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2569, 163)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just in case you wanna see the preprocessed data (bevor it is passed to sampler)\n",
    "preprocessed_data = pd.DataFrame(preprocessor.transform(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Preprocessor / Pipeline to get the feature names\n",
    "\n",
    "StandardScaler and built-in passthrough argument of ColumnTransformer do not yet provide get_feature_names(). That's why I have substituted the StandardScaler with a custom PassthroughTransformer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"assemble pipeline (define function)\"\"\"\n",
    "\n",
    "def build_feature_pipe(X_train, y_train, clf, sampler):\n",
    "    \"\"\"Build a pipeline for preprocessing (including oversampling)\n",
    "    and classification.\n",
    "    \n",
    "    ARGUMENTS:\n",
    "        X_train: training features (df or array)\n",
    "        y_train: training labels (df or array)\n",
    "        clf: classifier (sk-learn model object)\n",
    "        sampler: sampler (imblearn sampling class)\n",
    "        \n",
    "    RETURNS:\n",
    "        full_pipe: pipeline object\n",
    "    \"\"\"\n",
    " \n",
    "    preprocessor = ColumnTransformer([\n",
    "            ('ohe', OneHotEncoder(), cat_features),\n",
    "            ('pass', transform.PassthroughTransformer(), num_features), # new step, does not change data\n",
    "            ])\n",
    "    \n",
    "    full_pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('sample', sampler),\n",
    "        ('clf', clf)])\n",
    "    \n",
    "    return preprocessor, full_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r2d4\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ohe__x0_1.0',\n",
       " 'ohe__x0_2.0',\n",
       " 'ohe__x0_3.0',\n",
       " 'ohe__x0_4.0',\n",
       " 'ohe__x0_5.0',\n",
       " 'ohe__x0_6.0',\n",
       " 'ohe__x0_7.0',\n",
       " 'ohe__x0_8.0',\n",
       " 'ohe__x0_9.0',\n",
       " 'ohe__x0_10.0',\n",
       " 'ohe__x0_11.0',\n",
       " 'ohe__x0_12.0',\n",
       " 'ohe__x0_13.0',\n",
       " 'ohe__x0_14.0',\n",
       " 'ohe__x0_15.0',\n",
       " 'ohe__x0_16.0',\n",
       " 'ohe__x0_17.0',\n",
       " 'ohe__x0_18.0',\n",
       " 'ohe__x0_19.0',\n",
       " 'ohe__x0_20.0',\n",
       " 'ohe__x0_21.0',\n",
       " 'ohe__x0_22.0',\n",
       " 'ohe__x0_23.0',\n",
       " 'ohe__x0_24.0',\n",
       " 'ohe__x0_25.0',\n",
       " 'ohe__x0_26.0',\n",
       " 'ohe__x0_27.0',\n",
       " 'ohe__x0_28.0',\n",
       " 'ohe__x0_29.0',\n",
       " 'ohe__x0_30.0',\n",
       " 'ohe__x0_31.0',\n",
       " 'ohe__x0_32.0',\n",
       " 'ohe__x0_33.0',\n",
       " 'ohe__x0_34.0',\n",
       " 'ohe__x0_35.0',\n",
       " 'ohe__x0_36.0',\n",
       " 'ohe__x0_37.0',\n",
       " 'ohe__x1_0.0',\n",
       " 'ohe__x1_1.0',\n",
       " 'pass__Company',\n",
       " 'pass__Time',\n",
       " 'pass__x1',\n",
       " 'pass__x2',\n",
       " 'pass__x3',\n",
       " 'pass__x4',\n",
       " 'pass__x5',\n",
       " 'pass__x6',\n",
       " 'pass__x7',\n",
       " 'pass__x8',\n",
       " 'pass__x9',\n",
       " 'pass__x10',\n",
       " 'pass__x11',\n",
       " 'pass__x12',\n",
       " 'pass__x13',\n",
       " 'pass__x14',\n",
       " 'pass__x15',\n",
       " 'pass__x16',\n",
       " 'pass__x17',\n",
       " 'pass__x18',\n",
       " 'pass__x19',\n",
       " 'pass__x20',\n",
       " 'pass__x21',\n",
       " 'pass__x22',\n",
       " 'pass__x23',\n",
       " 'pass__x24',\n",
       " 'pass__x25',\n",
       " 'pass__x26',\n",
       " 'pass__x27',\n",
       " 'pass__x28',\n",
       " 'pass__x29',\n",
       " 'pass__x30',\n",
       " 'pass__x31',\n",
       " 'pass__x32',\n",
       " 'pass__x33',\n",
       " 'pass__x34',\n",
       " 'pass__x35',\n",
       " 'pass__x36',\n",
       " 'pass__x37',\n",
       " 'pass__x38',\n",
       " 'pass__x39',\n",
       " 'pass__x40',\n",
       " 'pass__x41',\n",
       " 'pass__x42',\n",
       " 'pass__x43',\n",
       " 'pass__x44',\n",
       " 'pass__x45',\n",
       " 'pass__x46',\n",
       " 'pass__x47',\n",
       " 'pass__x48',\n",
       " 'pass__x49',\n",
       " 'pass__x50',\n",
       " 'pass__x51',\n",
       " 'pass__x52',\n",
       " 'pass__x53',\n",
       " 'pass__x54',\n",
       " 'pass__x55',\n",
       " 'pass__x56',\n",
       " 'pass__x57',\n",
       " 'pass__x58',\n",
       " 'pass__x59',\n",
       " 'pass__x60',\n",
       " 'pass__x61',\n",
       " 'pass__x62',\n",
       " 'pass__x63',\n",
       " 'pass__x64',\n",
       " 'pass__x65',\n",
       " 'pass__x66',\n",
       " 'pass__x67',\n",
       " 'pass__x68',\n",
       " 'pass__x69',\n",
       " 'pass__x70',\n",
       " 'pass__x71',\n",
       " 'pass__x72',\n",
       " 'pass__x73',\n",
       " 'pass__x74',\n",
       " 'pass__x75',\n",
       " 'pass__x76',\n",
       " 'pass__x77',\n",
       " 'pass__x78',\n",
       " 'pass__x79',\n",
       " 'pass__x80',\n",
       " 'pass__x81',\n",
       " 'pass__x82',\n",
       " 'pass__x83',\n",
       " 'pass__x84',\n",
       " 'pass__x85',\n",
       " 'pass__x86',\n",
       " 'pass__x87',\n",
       " 'pass__x88',\n",
       " 'pass__x89',\n",
       " 'pass__x90',\n",
       " 'pass__x91',\n",
       " 'pass__x92',\n",
       " 'pass__x93',\n",
       " 'pass__x94',\n",
       " 'pass__x95',\n",
       " 'pass__x96',\n",
       " 'pass__x97',\n",
       " 'pass__x98',\n",
       " 'pass__x100',\n",
       " 'pass__x101',\n",
       " 'pass__x102',\n",
       " 'pass__x103',\n",
       " 'pass__x104',\n",
       " 'pass__x105',\n",
       " 'pass__x106',\n",
       " 'pass__x107',\n",
       " 'pass__x108',\n",
       " 'pass__x109',\n",
       " 'pass__x110',\n",
       " 'pass__x111',\n",
       " 'pass__x112',\n",
       " 'pass__x113',\n",
       " 'pass__x114',\n",
       " 'pass__x115',\n",
       " 'pass__x116',\n",
       " 'pass__x117',\n",
       " 'pass__x118',\n",
       " 'pass__x119',\n",
       " 'pass__x120',\n",
       " 'pass__x122',\n",
       " 'pass__x123',\n",
       " 'pass__x124']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"fit and get feature names\"\"\"\n",
    "feature_preprocessor, feature_pipe = build_feature_pipe(X_train, y_train, gbc, sampler)\n",
    "feature_preprocessor.fit(X_train)\n",
    "feature_preprocessor.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
