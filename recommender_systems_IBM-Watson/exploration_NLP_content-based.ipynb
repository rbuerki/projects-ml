{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration: NLP for Content Based Recommendations\n",
    "\n",
    "The purpose of this notebook is to do some EDA and NLP on the content data. The Results will then be used in the \"Content Based\" section of the main notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'stopwords', 'averaged_perceptron_tagger', 'maxent_ne_chunker', 'words'])\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(); color='rebeccapurple'\n",
    "%matplotlib inline  \n",
    "\n",
    "# display settings\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load content data\n",
    "\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df_content['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1056 entries, 0 to 1055\n",
      "Data columns (total 5 columns):\n",
      "doc_body           1042 non-null object\n",
      "doc_description    1053 non-null object\n",
      "doc_full_name      1056 non-null object\n",
      "doc_status         1056 non-null object\n",
      "article_id         1056 non-null int64\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 41.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_content.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VIDEO IS UNAVAILABLE.\\r\\nWATCH QUEUE\\r\\nQUEUE\\r\\nWatch Queue Queue * Remove all\\r\\n * Disconnect\\r\\n\\r\\nThe next ...</td>\n",
       "      <td>Detect bad readings in real time using Python and Streaming Analytics.</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streaming Analytics</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data science: A guide to presenting your work 4COMMUNICATING DATA SCIENCE: A GUIDE TO PRESENTING YOUR WORK\\r\\nMegan ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the challenge in both performing and presenting an analysis. As data scientists, analysts, and machine learning engineers faced with fulfilling business obj‚Ä¶</td>\n",
       "      <td>Communicating data science: A guide to presenting your work</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‚ò∞ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Paths\\r\\n * Courses * Our Courses\\r\\n    * Partner Courses\\r\\n   \\r\\n   \\r\\n * Badges * Our Badges\\r\\n    * BDU Badge Program\\r\\n   \\r\\n   \\r\\n * Watson ...</td>\n",
       "      <td>Here‚Äôs this week‚Äôs news in Data Science and Big Data.</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCALE - BOOST THE PERFORMANCE OF YOUR\\r\\nDISTRIBUTED DATABASE\\r\\nShare on Twitter Share on Facebook Share on Google+ Vote on Hacker News Published Dec 29...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of scaling persistent storage, but introduce latency as data size increases and become I/O bound.</td>\n",
       "      <td>DataLayer Conference: Boost the performance of your distributed database</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VIDEO IS UNAVAILABLE.\\r\\nWATCH QUEUE\\r\\nQUEUE\\r\\nWatch Queue Queue * Remove all\\r\\n * Disconnect\\r\\n\\r\\nThe next ...</td>\n",
       "      <td>This video demonstrates the power of IBM DataScience Experience using a simple New York State Restaurant Inspections data scenario.</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                  doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VIDEO IS UNAVAILABLE.\\r\\nWATCH QUEUE\\r\\nQUEUE\\r\\nWatch Queue Queue * Remove all\\r\\n * Disconnect\\r\\n\\r\\nThe next ...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data science: A guide to presenting your work 4COMMUNICATING DATA SCIENCE: A GUIDE TO PRESENTING YOUR WORK\\r\\nMegan ...   \n",
       "2  ‚ò∞ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Paths\\r\\n * Courses * Our Courses\\r\\n    * Partner Courses\\r\\n   \\r\\n   \\r\\n * Badges * Our Badges\\r\\n    * BDU Badge Program\\r\\n   \\r\\n   \\r\\n * Watson ...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCALE - BOOST THE PERFORMANCE OF YOUR\\r\\nDISTRIBUTED DATABASE\\r\\nShare on Twitter Share on Facebook Share on Google+ Vote on Hacker News Published Dec 29...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VIDEO IS UNAVAILABLE.\\r\\nWATCH QUEUE\\r\\nQUEUE\\r\\nWatch Queue Queue * Remove all\\r\\n * Disconnect\\r\\n\\r\\nThe next ...   \n",
       "\n",
       "                                                                                                                                                                                          doc_description  \\\n",
       "0                                                                                                                                  Detect bad readings in real time using Python and Streaming Analytics.   \n",
       "1  See the forest, see the trees. Here lies the challenge in both performing and presenting an analysis. As data scientists, analysts, and machine learning engineers faced with fulfilling business obj‚Ä¶   \n",
       "2                                                                                                                                                   Here‚Äôs this week‚Äôs news in Data Science and Big Data.   \n",
       "3                                                           Learn how distributed DBs solve the problem of scaling persistent storage, but introduce latency as data size increases and become I/O bound.   \n",
       "4                                                                    This video demonstrates the power of IBM DataScience Experience using a simple New York State Restaurant Inspections data scenario.    \n",
       "\n",
       "                                                              doc_full_name  \\\n",
       "0                Detect Malfunctioning IoT Sensors with Streaming Analytics   \n",
       "1               Communicating data science: A guide to presenting your work   \n",
       "2                                This Week in Data Science (April 18, 2017)   \n",
       "3  DataLayer Conference: Boost the performance of your distributed database   \n",
       "4                             Analyze NY Restaurant data using Spark in DSX   \n",
       "\n",
       "  doc_status  article_id  \n",
       "0       Live           0  \n",
       "1       Live           1  \n",
       "2       Live           2  \n",
       "3       Live           3  \n",
       "4       Live           4  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     681\n",
       "1    3430\n",
       "2     806\n",
       "3     285\n",
       "Name: doc_body, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.loc[:3, 'doc_body'].apply(lambda x : len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze mean text length in words by column\n",
    "\n",
    "def get_mean_length(col):\n",
    "    \n",
    "    length_list = []\n",
    "    \n",
    "    for row in df_content[col]:\n",
    "        try:\n",
    "            length = len(row.split())\n",
    "            length_list.append(length)\n",
    "        \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    mean_length = round(np.mean(length_list), 0)\n",
    "    std_length = round(np.std(length_list), 0)\n",
    "    \n",
    "    print(str(col), mean_length, std_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_body 1294.0 996.0\n",
      "doc_description 28.0 15.0\n",
      "doc_full_name 7.0 3.0\n"
     ]
    }
   ],
   "source": [
    "# call the function\n",
    "\n",
    "cols = ['doc_body', 'doc_description', 'doc_full_name']\n",
    "\n",
    "for col in cols:\n",
    "    get_mean_length(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip navigation Sign in SearchLoading...\r\n",
      "\r\n",
      "Close Yeah, keep it Undo CloseTHIS VIDEO IS UNAVAILABLE.\r\n",
      "WATCH QUEUE\r\n",
      "QUEUE\r\n",
      "Watch Queue Queue * Remove all\r\n",
      " * Disconnect\r\n",
      "\r\n",
      "The next video is starting stop 1. Loading...\r\n",
      "\r\n",
      "Watch Queue Queue __count__/__total__ Find out why CloseDEMO: DETECT MALFUNCTIONING IOT SENSORS WITH STREAMING ANALYTICS\r\n",
      "IBM AnalyticsLoading...\r\n",
      "\r\n",
      "Unsubscribe from IBM Analytics? Cancel UnsubscribeWorking...\r\n",
      "\r\n",
      "Subscribe Subscribed Unsubscribe 26KLoading...\r\n",
      "\r\n",
      "Loading...\r\n",
      "\r\n",
      "Working...\r\n",
      "\r\n",
      "Add toWANT TO WATCH THIS AGAIN LATER?\r\n",
      "Sign in to add this video to a playlist. Sign in Share More * ReportNEED TO REPORT THE VIDEO?\r\n",
      "   Sign in to report inappropriate content. Sign in\r\n",
      " * Transcript\r\n",
      " * Statistics\r\n",
      " * Add translations\r\n",
      "\r\n",
      "175 views 6LIKE THIS VIDEO?\r\n",
      "Sign in to make your opinion count. Sign in 7 0DON'T LIKE THIS VIDEO?\r\n",
      "Sign in to make your opinion count. Sign in 1Loading...\r\n",
      "\r\n",
      "Loading...\r\n",
      "\r\n",
      "TRANSCRIPT\r\n",
      "The interactive transcript could not be loaded.Loading...\r\n",
      "\r\n",
      "Loading...\r\n",
      "\r\n",
      "Rating is available when the video has been rented. This feature is not available right now. Please try again later. Published on Nov 6, 2017This video demonstrates a Streaming Analytics application written in Python\r\n",
      "running in the IBM Data Science experience. The results of the analysis are\r\n",
      "displayed on a map using Plotly.\r\n",
      "\r\n",
      "The notebook demonstrated in this video is available for you to try: http://ibm.biz/WeatherNotebook\r\n",
      "\r\n",
      "Visit Streamsdev for more articles and tips about Streams: https://developer.ibm.com/streamsdev\r\n",
      "\r\n",
      "Python API Developer guide: http://ibmstreams.github.io/streamsx....\r\n",
      "\r\n",
      "Streaming Analytics in Python course: https://developer.ibm.com/courses/all...\r\n",
      "\r\n",
      " * CATEGORY\r\n",
      "    * Science & Technology\r\n",
      "   \r\n",
      "   \r\n",
      " * LICENSE\r\n",
      "    * Standard YouTube License\r\n",
      "   \r\n",
      "   \r\n",
      "\r\n",
      "Show more Show lessLoading...\r\n",
      "\r\n",
      "Autoplay When autoplay is enabled, a suggested video will automatically play next.UP NEXT\r\n",
      " * The Python ecosystem for Data Science: A guided tour - Christian Staudt -\r\n",
      "   Duration: 25:41. PyData 1,411 views 25:41\r\n",
      "\r\n",
      "\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "\r\n",
      " * IBM Streaming Analytics and Python - Duration: 1:00:51. John O'Neill 105\r\n",
      "   views 1:00:51\r\n",
      " * How Customers Are Using the IBM Data Science Experience Expected Cases and\r\n",
      "   Not So Expected Ones - Duration: 18:29. Databricks 327 views 18:29\r\n",
      " * Giovanni Lanzani | Applied Data Science - Duration: 35:14. PyData 2,728 views 35:14\r\n",
      " * Detecting Fraud in Real-Time with Azure Stream Analytics - Duration: 32:16.\r\n",
      "   Philip Howard 71 views 32:16\r\n",
      " * Step by step guide how to build a real-time anomaly detection system using\r\n",
      "   Apache Spark Streaming - Duration: 16:11. Mariusz Jacyno 4,591 views 16:11\r\n",
      " * Real-time Analytics with Azure Stream Analytics - Duration: 54:47. PASS\r\n",
      "   Business Analytics Virtual Group 940 views 54:47\r\n",
      " * Real-Time Machine Learning Analytics Using Structured Streaming and Kinesis\r\n",
      "   Firehose - Duration: 31:25. Databricks 660 views 31:25\r\n",
      " * Data Science - Duration: 25:05. manish telang 3 views 25:05\r\n",
      " * Real-Time Log Analytics using Amazon Kinesis and Amazon Elasticsearch Service\r\n",
      "   - Duration: 28:32. Amazon Web Services - Webinar Channel 1,072 views 28:32\r\n",
      " * IBM Data Science Experience and Machine Learning Use Cases in Healthcare -\r\n",
      "   Duration: 26:53. IDEAS 157 views 26:53\r\n",
      " * Streaming Analytics Comparison of Open Source Frameworks, Products, Cloud\r\n",
      "   Services - Duration: 47:06. Kai W√§hner 1,761 views 47:06\r\n",
      " * An overview of IBM Streaming Analytics for Bluemix - Duration: 44:12. IBM\r\n",
      "   Analytics 1,311 views 44:12\r\n",
      " * Predicting Stock Prices - Learn Python for Data Science #4 - Duration: 7:39.\r\n",
      "   Siraj Raval 274,452 views 7:39\r\n",
      " * REST API concepts and examples - Duration: 8:53. WebConcepts 1,687,034 views 8:53\r\n",
      " * Streaming Data Analytics with Apache Spark Streaming - Duration: 1:01:19.\r\n",
      "   Data Gurus 300 views 1:01:19\r\n",
      " * Orchestrate IBM Data Science Experience analytics workflows using Node-RED -\r\n",
      "   Duration: 10:16. Balaji Kadambi 109 views 10:16\r\n",
      " * Delight Clients with Data Science on the IBM Integrated Analytics System -\r\n",
      "   Duration: 15:05. IBM Analytics 1,581 views 15:05\r\n",
      " * What is DevOps? - In Simple English - Duration: 7:07. Rackspace 657,396 views 7:07\r\n",
      " * Introduction - Learn Python for Data Science #1 - Duration: 6:55. Siraj Raval\r\n",
      "   206,552 views 6:55\r\n",
      " * Loading more suggestions...\r\n",
      " * Show more\r\n",
      "\r\n",
      " * Language: English\r\n",
      " * Location: United States\r\n",
      " * Restricted Mode: Off\r\n",
      "\r\n",
      "History HelpLoading...\r\n",
      "\r\n",
      "Loading...\r\n",
      "\r\n",
      "Loading...\r\n",
      "\r\n",
      " * About\r\n",
      " * Press\r\n",
      " * Copyright\r\n",
      " * Creators\r\n",
      " * Advertise\r\n",
      " * Developers\r\n",
      " * +YouTube\r\n",
      "\r\n",
      " * Terms\r\n",
      " * Privacy\r\n",
      " * Policy & Safety\r\n",
      " * Send feedback\r\n",
      " * Test new features\r\n",
      " * \r\n",
      "\r\n",
      "Loading...\r\n",
      "\r\n",
      "Working...\r\n",
      "\r\n",
      "Sign in to add this to Watch LaterADD TO\r\n",
      "Loading playlists...\n",
      "No Free Hunch Navigation * kaggle.com\r\n",
      "\r\n",
      " * kaggle.com\r\n",
      "\r\n",
      "Communicating data science: A guide to presenting your work 4COMMUNICATING DATA SCIENCE: A GUIDE TO PRESENTING YOUR WORK\r\n",
      "Megan Risdal | 06.29.2016\r\n",
      "\r\n",
      "See the forest, see the trees . Here lies the challenge in both performing and presenting an analysis. As\r\n",
      "data scientists, analysts, and machine learning engineers faced with fulfilling\r\n",
      "business objectives, we find ourselves bridging the gap between The Two Cultures : sciences and humanities. After spending countless hours at the terminal\r\n",
      "devising a creative and elegant solution to a difficult problem, the insights\r\n",
      "and business applications are obvious in our minds. But how do you distill them\r\n",
      "into something you can communicate?\r\n",
      "\r\n",
      "Qualifications and requirements for a senior data scientist position.\r\n",
      "\r\n",
      "Presenting my work is one of the surprising challenges I faced in my recent\r\n",
      "transition from academia to life as a data analyst at a market research and strategy firm . When I was a linguistics PhD student at UCLA studying learnability theory in\r\n",
      "a classroom or measuring effects of an oral constriction on glottal vibration in\r\n",
      "a sound booth, my colleagues and I were comfortable speaking the same language.\r\n",
      "Now that I work with a much more diverse crowd of co-workers and clients with\r\n",
      "varied backgrounds and types of expertise, I need to work harder to ensure that\r\n",
      "the insights of my analyses are communicated effectively.\r\n",
      "\r\n",
      "In this second entry in the communicating data science series , I cover some essentials when it comes to presenting a thorough,\r\n",
      "comprehensible analysis for readers who want (or need) to know how to get their\r\n",
      "work noticed and read.\r\n",
      "\r\n",
      "\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "\r\n",
      "GET YOUR HEAD IN THE GAME\r\n",
      "Imagine you‚Äôve just completed the so-called heavy lifting, whatever it may be,\r\n",
      "and you‚Äôre ready to present your results and conclusions in a report. Well, step\r\n",
      "away from the word processor! There are two things you must first consider: your\r\n",
      "audience and your goals. This is your forest.\r\n",
      "\r\n",
      "WHO IS YOUR AUDIENCE?\r\n",
      "The matter of who you‚Äôre speaking to will influence every detail of how you\r\n",
      "choose to present your analysis from whether you use technical jargon or spend\r\n",
      "time carefully defining your terms. The formality of the context may determine\r\n",
      "whether a short, fun tangent or personal anecdote will keep your audience\r\n",
      "happily engaged or elicit eye rolls ‚Ä¶ and worse.\r\n",
      "\r\n",
      "This is all important to consider because once you‚Äôve envisioned your audience,\r\n",
      "you take stock of what may and may not be shared knowledge and how to manage\r\n",
      "their expectations. In your writing (and in everyday life), it‚Äôs useful to be\r\n",
      "cognizant of Grice‚Äôs principles of cooperative communication:\r\n",
      "\r\n",
      " 1. Maxim of quantity : be informative, without giving overwhelming amounts of extraneous detail.\r\n",
      " 2. Maxim of quality : be truthful. Enough said.\r\n",
      " 3. Maxim of relation : be relevant. I‚Äôll give you some tips on staying topical shortly!\r\n",
      " 4. Maxim of manner : be clear. Don‚Äôt be ambiguous, be orderly.\r\n",
      "\r\n",
      "So be cooperative! Know your audience and do what you can to anticipate their\r\n",
      "expectations. This will ensure that you cover all ground in exactly as much\r\n",
      "detail as necessary in your report.\r\n",
      "\r\n",
      "WHAT IS THE GOAL?\r\n",
      "Also before you put pen to paper, it‚Äôs helpful remind yourself again (and again)\r\n",
      "of what your goal is. If you‚Äôre working in a professional environment, you‚Äôre\r\n",
      "aware that it‚Äôs important to be continually mindful of the goal or business\r\n",
      "problem and why you‚Äôre tasked with solving it.\r\n",
      "\r\n",
      "Or perhaps it's a strategic initiative you're after: Did you set out to learn\r\n",
      "something new about some data (and the world)? Or have you been diligently\r\n",
      "working on a new skill you‚Äôd like to showcase? Do you want to test out some\r\n",
      "ideas and get feedback? It‚Äôs okay to make it your goal to find out ‚ÄúCan I do\r\n",
      "this?‚Äù Maybe you want to share some of your expertise with the community on\r\n",
      "Kaggle Scripts. In that case, it‚Äôs even more imperative that you have a\r\n",
      "buttoned-up analysis!\r\n",
      "\r\n",
      "\"If we can really understand the problem, the answer will come out of it,\r\n",
      "because the answer is not separate from the problem.\"\r\n",
      "\r\n",
      "‚Äï Jiddu KrishnamurtiIf you‚Äôve reached the point of having an analysis to report, you‚Äôve more than\r\n",
      "likely familiarized yourself with the goals of the initiative, but you must also\r\n",
      "keep them at the forefront of your thoughts when presenting your results as\r\n",
      "well. Your work should be contextualized in terms of your understanding of the\r\n",
      "research objectives. Often in my own day job this means synthesizing many\r\n",
      "analyses I‚Äôve performed into a few key pieces of evidence which support a story;\r\n",
      "this can‚Äôt be done well except by accident without keeping in mind the ultimate\r\n",
      "objective at hand.\r\n",
      "\r\n",
      "THE PREAMBLE\r\n",
      "Now that you‚Äôve got yourself in the right frame of mind‚Äïyou can see the forest\r\n",
      "and you know the trees‚Äïyou‚Äôre ready to start thinking about the content of your\r\n",
      "report. However, before you start furiously spilling ink, first remind yourself\r\n",
      "of the three elements required to ask an askable question in science:\r\n",
      "\r\n",
      " 1. The question itself along with some justification of how it addresses your\r\n",
      "    objectives\r\n",
      " 2. A hypothesis\r\n",
      " 3. A feasible methodology for addressing your question\r\n",
      "\r\n",
      "Much as I implore you to consider who your audience is and what your objectives\r\n",
      "are in order to get your mind in the right place, I‚Äôm recommending that you have\r\n",
      "the answers to these three things ready because they will dictate the content of\r\n",
      "your report. You don‚Äôt want to throw everything and the kitchen sink into a\r\n",
      "report!\r\n",
      "\r\n",
      "WHAT‚ÄôS THE QUESTION?\r\n",
      "On Kaggle, the competition hosts very generously provide their burning questions\r\n",
      "to the community. Outside of this environment, the challenge is to come up with\r\n",
      "one on your own or work within the business objectives of your employer. At this\r\n",
      "point, you make sure that you can appropriately state the question and how it\r\n",
      "relates to your objective(s).\r\n",
      "\r\n",
      "As an aside, if you need some exercise in the area of asking insightful\r\n",
      "questions (a skill unto its own), I hereby challenge you to scroll through some\r\n",
      "of Kagglers‚Äô most recent scripts, find and read one, and think of one new\r\n",
      "question you could ask the author. If you find that this is a stumbling block\r\n",
      "preventing you from proceeding with your analysis, many dataset publishers\r\n",
      "include a number of questions they‚Äôd like to see addressed. Or read the Script of the Week blogs and see what other ideas script authors would like to see explored in the same\r\n",
      "dataset.\r\n",
      "\r\n",
      "WHAT‚ÄôS THE ANSWER?\r\n",
      "Now that you have your question, what do you think the answer will be? It‚Äôs good\r\n",
      "practice, of course, to consider what the possible answers may be before you dig\r\n",
      "into the data, so hopefully you‚Äôve already done that! Clearly delimiting the\r\n",
      "hypothesis space at this point will guide the evidence and arguments you use in\r\n",
      "the body of your report. It will be easier to evaluate what constitutes weak and\r\n",
      "strong support of your theory and what analyses may be absolutely irrelevant.\r\n",
      "Ultimately you will prevent yourself from attacking straw men in faux support of your theory.\r\n",
      "\r\n",
      "Don't build straw men.\r\n",
      "\r\n",
      "WHAT‚ÄôS YOUR METHODOLOGY?\r\n",
      "Let‚Äôs say you‚Äôre asking whether Twitter users with dense social networks in the How ISIS Uses Twitter dataset express greater negative sentiment than users with less dense networks. Your\r\n",
      "first step is to confirm that the data available is sufficient to address your\r\n",
      "research question. If there‚Äôs major missing information, you may want to rethink\r\n",
      "your question, revise your methodology, or even collect new data.\r\n",
      "\r\n",
      "If you‚Äôre unsure of how to put language to a particular methodology, this is a\r\n",
      "good opportunity to flex your Googling skills. Search for ‚Äúsocial network\r\n",
      "analysis in r‚Äù or ‚Äúsentiment analysis in python.‚Äù Dive into some academic papers\r\n",
      "if it's appropriate and see how it's presented. Peruse the natural language processing tags on No Free Hunch and read the winners‚Äô interviews . Get inspiration from scripts on similar datasets on Kaggle. For example, a similar analysis was performed by Kaggle user Khomutov Nikita using the Hillary Clinton‚Äôs Emails dataset .\r\n",
      "\r\n",
      "Hillary Clinton's network graph. See the code here .\r\n",
      "\r\n",
      "Even if you don‚Äôt end up needing to share every nuance of your methodology with\r\n",
      "your given audience, you should always document your work thoroughly to the\r\n",
      "extent possible. Once you‚Äôre ready to present your analysis, you‚Äôll be capable\r\n",
      "of determining how much is the right amount to share when discussing the nitty\r\n",
      "gritty mechanics of your model. Similarly, I've been able to pleasantly surprise\r\n",
      "my boss many times because I have an answer ready at-hand for immediate\r\n",
      "questions thanks to keeping my exploratory analyses well-documented.\r\n",
      "\r\n",
      "By the way, if you‚Äôve felt overwhelmed by the task of putting together a solid\r\n",
      "methodology for tackling a question, it can‚Äôt hurt to lob an idea and some code\r\n",
      "to the community for feedback. Especially once you have solid presentation of\r\n",
      "analysis skills! Be honest about where you feel you could use extra input and\r\n",
      "maybe a fellow Kaggler will come forth with different angle on the problem.\r\n",
      "\r\n",
      "PUTTING THE PIECES TOGETHER\r\n",
      "Finally, you‚Äôre ready to write. Keep in mind that a good analysis should\r\n",
      "facilitate its own interpretation as much as possible. Again, this requires\r\n",
      "anticipating what information your likely audience will be seeking and what\r\n",
      "knowledge they‚Äôre coming in with already. One method which is both\r\n",
      "tried-and-true and friendly to the academic nature of the discipline is\r\n",
      "following a template for your analysis. With that, this section covers the\r\n",
      "structure which when fleshed out will help you tell the story in the data.\r\n",
      "\r\n",
      "Keep in mind that a good analysis should facilitate its own interpretation as\r\n",
      "much as possible.\r\n",
      "\r\n",
      "NOT SO ABSTRACT\r\n",
      "Make it easy for your audience to quickly determine what they‚Äôre about to\r\n",
      "digest. Use an abstract or introduction to recall your objectives and clearly\r\n",
      "state them for your readers. What is the problem that you‚Äôve set out to solve?\r\n",
      "If you have a desired outcome or any expectations of your audience, say it, as\r\n",
      "this is the entire reason you‚Äôre presenting them with your analysis.\r\n",
      "\r\n",
      "You then cover everything from your preamble in this section: the question\r\n",
      "you‚Äôve been on a mission to answer, your hypothesis, and the methodology you‚Äôve\r\n",
      "used. Finally, you will often provide a high level summary of your results and\r\n",
      "key findings. Don‚Äôt worry about spoiler alerts or boring your readers to death\r\n",
      "with the content that‚Äôs about to follow. Trust that if they pay attention past\r\n",
      "the introduction that they are interested in how you achieve what you claim you\r\n",
      "have.\r\n",
      "\r\n",
      "Many people I've talked to have said that they often find it easier to write the\r\n",
      "abstract after having already completely documented the detailed findings of the analysis. I\r\n",
      "think that this is at least in part because you've familiarized yourself with\r\n",
      "your own work through the lens of your readership by doing so. Slowly but surely\r\n",
      "you're extracting yourself from the trees and the bigger picture becomes\r\n",
      "apparent.\r\n",
      "\r\n",
      "THE CONTENT: BREAK OFF WHAT YOU CAN CHEW\r\n",
      "This is where the good stuff lives. You've laid the foundation for your analysis\r\n",
      "such that your audience is prepared to read or listen intently to your story. I\r\n",
      "can‚Äôt tell you the specifics of what goes here, but I can tell you how to\r\n",
      "structure it.\r\n",
      "\r\n",
      "Take your analysis in small bits by breaking your question into subparts. For a\r\n",
      "data-driven analysis, it can make sense to tackle each piece of evidence\r\n",
      "one-by-one. You may have a dissertation‚Äôs worth of data to report on, but more\r\n",
      "likely than not you must pick and choose what will best support your analysis\r\n",
      "succinctly and effectively. Again, having the objectives and audience in mind\r\n",
      "will help you decide what‚Äôs critical. Lay it all out before you and pair\r\n",
      "sub-questions with evidence until you have a story.\r\n",
      "\r\n",
      "Once you‚Äôve presented the evidence, explain why it supports (or doesn't support)\r\n",
      "your hypothesis or your objectives. A good analysis also considers alternative\r\n",
      "hypotheses or interpretations as well. You‚Äôve already surveyed the hypothesis\r\n",
      "space, so you should be ready-armed to handle contrary evidence. Doing so is\r\n",
      "also a way of anticipating the expectations of your audience and the skepticism\r\n",
      "they may harbor. It‚Äôs at this point that it‚Äôs most critical to keep in mind your\r\n",
      "objectives and the question you‚Äôre addressing with your analysis. Ask how every\r\n",
      "piece of evidence you offer takes you one step closer to confirming or\r\n",
      "disproving your hypothesis.\r\n",
      "\r\n",
      "OTHER TIPS AND TRICKS\r\n",
      "Visualize the problem . Seeing is believing. It‚Äôs cliched to say in any statement asserting the value\r\n",
      "of data visualization, but it‚Äôs so incredibly true. This ‚Äútrick‚Äù is so effective\r\n",
      "that I‚Äôm going to spend more time talking about it in a future post. If you can\r\n",
      "plainly ‚Äústate‚Äù something with a graph or chart, go for it!\r\n",
      "\r\n",
      " * Shail Jayesh Deliwala visualizes confusion matrices to evaluate and compare model performance.\r\n",
      "   Read the full notebook here .\" /\r\n",
      " * Lj Miranda shows the steady rise of carbon emissions in the Philippines. Read the full\r\n",
      "   notebook here .\" /\r\n",
      " * 33Vito uses polar coordinates to show the times during the day leveling and\r\n",
      "   non-leveling characters play World of Warcraft. Read the full notebook here .\" /\r\n",
      " * Michael Griffiths uses color and variations in transparency to make this table of percentages\r\n",
      "   more readily interpretable. Read the full notebook here .\" /\r\n",
      "\r\n",
      " * Shail Jayesh Deliwala visualizes confusion matrices to evaluate and compare model performance.\r\n",
      "   Read the full notebook here .\" /\r\n",
      " * Lj Miranda shows the steady rise of carbon emissions in the Philippines. Read the full\r\n",
      "   notebook here .\" /\r\n",
      " * 33Vito uses polar coordinates to show the times during the day leveling and\r\n",
      "   non-leveling characters play World of Warcraft. Read the full notebook here .\" /\r\n",
      " * Michael Griffiths uses color and variations in transparency to make this table of percentages\r\n",
      "   more readily interpretable. Read the full notebook here .\" /\r\n",
      "\r\n",
      "Variety is the spice of life . And it can liven up your writing (and speaking) as well. For example, use a\r\n",
      "mix of short and sweet sentences interspersed among longer, more elaborate ones.\r\n",
      "Find where you accidentally used the word ‚Äúdidactic‚Äù four times on one page and\r\n",
      "change it up! Related to my first point, use effective variety in types of\r\n",
      "visualizations you employ. Small things like this will keep your readers awake\r\n",
      "and interested.\r\n",
      "\r\n",
      "Check your work . I don‚Äôt like to emphasize this too much because I‚Äôm a descriptivist , but make sure your writing is grammatical, fluent, and free of typos. For\r\n",
      "better or worse, trivial mistakes can discredit you in the eyes of many. I find\r\n",
      "that it helps to read my writing aloud to catch disfluencies.\r\n",
      "\r\n",
      "Gain muscle memory . If you really struggle with transforming your analysis into a form that can\r\n",
      "be shared more broadly, begin by writing anything until writing prose feels as natural as writing code. For example, I actually\r\n",
      "suggest sitting down and copying a report word-for-word. Or even any instance of\r\n",
      "persuasive writing. Not to be used as your own in any way (i.e., plagiarism),\r\n",
      "but to remove one more unknown from the equation: what it literally feels like to go through the motions of stringing words and sentences and paragraphs\r\n",
      "together to tell a story.\r\n",
      "\r\n",
      "CONCLUSIONS & NEXT STEPS\r\n",
      "A good analysis is repetitive. You know the intricacies of your work in and out,\r\n",
      "but your audience does not. You‚Äôve told your readers in your abstract (or\r\n",
      "introduction, if you prefer) what you had ventured to do and even what you end\r\n",
      "up finding and the content lays this all out for them. In the conclusions\r\n",
      "section you hit them with it again. At this point, they‚Äôve seen the relevant\r\n",
      "data you‚Äôve carefully chosen to support your theory so it‚Äôs time to formally\r\n",
      "draw your conclusions. Your readers can decide if they agree or not.\r\n",
      "\r\n",
      "Speaking of being repetitive, after making your conclusions, you again remind\r\n",
      "your readers of the objective(s) of this report. Restate them again and help\r\n",
      "your readers help you‚Äïwhat do you expect now? What feedback would you like? What\r\n",
      "decision-making can happen now that your report is presented and the insights\r\n",
      "have been shared? In my work, I often collaborate with strategists to develop a\r\n",
      "set of recommendations for our clients. Typically I'll take a stab at it based\r\n",
      "on the expertise I've gained in working with the data and a strategist will\r\n",
      "refine using their business insights.\r\n",
      "\r\n",
      "FIN\r\n",
      "And this is exactly where the beauty of the analysis and your skillful\r\n",
      "presentation thereof meet. Because you‚Äôve managed to package your approach in a\r\n",
      "fashion digestible to your audience, your readers, collaborators, and clients\r\n",
      "have comprehended and learned from your analysis and what its implications are\r\n",
      "without getting lost in the trees. They are equipped to react to the value in\r\n",
      "your work and participate in the next step of realizing its objectives.\r\n",
      "\r\n",
      "\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "\r\n",
      "Thanks for reading the second entry in this series on communicating data science . I covered the basics of presenting an analysis at a very high level. I'd love\r\n",
      "to learn what your approach is, how you realize the value in your work, and how\r\n",
      "you collaborate with others to achieve business goals. Leave a comment or send me a note !\r\n",
      "\r\n",
      "If you missed my interview with Tyler Byers, a data scientist and storytelling\r\n",
      "expert, check it out here . Stay tuned to learn some data visualization fundamentals.\r\n",
      "\r\n",
      "communicating data science data analysis Reporting Tutorial writing * Liling TanGricean maxims should be \"maxims\" of quantity, quality, relation and manner,\r\n",
      "   not \"maximums\" =)\r\n",
      "   \r\n",
      "    * Megan RisdalHaha, wow! I don't know how I did that. Fixed. Thank you! üôÇ\r\n",
      "      \r\n",
      "      \r\n",
      "    * \r\n",
      "   \r\n",
      "   \r\n",
      " * \r\n",
      " * Albert CampsVery interesting, thanks!!! Trying to summarize it ended up being quite long\r\n",
      "   anyway. A lot of distilled information.\r\n",
      "   \r\n",
      "   We work a bit differently. We include an executive summary + recommendations\r\n",
      "   at the beginning of the presentation instead of putting them at the end, just\r\n",
      "   after stating the question to answer. After that the audience knows what will\r\n",
      "   come, and when the presentation is revisited it is a lot faster to check . If\r\n",
      "   there's a need to dig deeper, there's always available all the analysis\r\n",
      "   steps.\r\n",
      "   \r\n",
      "   Hoping to see the next one soon! üòÄ\r\n",
      "   \r\n",
      "    * Megan RisdalThanks! I actually often do the same thing re: executive summaries in my\r\n",
      "      day job, too! That's a really good point. There's definitely no\r\n",
      "      one-size-fits-all approach which makes a high-level summarization\r\n",
      "      misleading in certain ways. And now that I think of it, another strength\r\n",
      "      in communicating data science is being able to be information dense &\r\n",
      "      concise for times where you need to fit your work into a standalone one-\r\n",
      "      or two-sheeter/executive summary.\r\n",
      "      \r\n",
      "      Hopefully more good stuff coming soon. üôÇ\r\n",
      "      \r\n",
      "      \r\n",
      "    * \r\n",
      "   \r\n",
      "   \r\n",
      " * \r\n",
      "\r\n",
      "THE OFFICIAL BLOG OF KAGGLE.COM\r\n",
      "SearchCATEGORIES\r\n",
      " * Data Science News (38)\r\n",
      " * Kaggle News (120)\r\n",
      " * Kernels (22)\r\n",
      " * Tutorials (28)\r\n",
      " * Winners' Interviews (174)\r\n",
      "\r\n",
      "WANT TO SUBSCRIBE?\r\n",
      "Email Address * First Name * = required fieldPOPULAR TAGS\r\n",
      "Algo Trading Challenge Annual Santa Competition binary classification community computer vision CrowdFlower Search Results Relevance Dark Matter Deloitte diabetes Diabetic Retinopathy EEG data Elo Chess Ratings Competition Eurovision Challenge Facebook Recruiting Flavours of Physics: Finding œÑ ‚Üí ŒºŒºŒº Flight Quest Grasp-and-Lift EEG Detection Heritage Health Prize How Much Did It Rain? image classification Intel Kaggle InClass Kernels logistic regression March Mania Merck multiclass classification natural language processing optimization problem Otto Product Classification Owen Zhang Practice Fusion Product Product News Profiling Top Kagglers Recruiting regression problem scikit-learn scripts of the week The Hunt for Prohibited Content Tourism Forecasting Tutorial video series Wikipedia Challenge XGBoostARCHIVES\r\n",
      "Archives Select Month July 2016 June 2016 May 2016 April 2016 March 2016 February 2016 January 2016 December 2015 November 2015 October 2015 September 2015 August 2015 July 2015 June 2015 May 2015 April 2015 March 2015 February 2015 January 2015 December 2014 November 2014 September 2014 August 2014 July 2014 June 2014 May 2014 April 2014 March 2014 February 2014 January 2014 December 2013 November 2013 September 2013 August 2013 July 2013 June 2013 May 2013 April 2013 March 2013 February 2013 January 2013 December 2012 November 2012 October 2012 September 2012 August 2012 July 2012 June 2012 May 2012 April 2012 March 2012 February 2012 January 2012 December 2011 November 2011 October 2011 September 2011 August 2011 July 2011 June 2011 May 2011 April 2011 March 2011 February 2011 January 2011 December 2010 November 2010 October 2010 September 2010 August 2010 July 2010 June 2010 May 2010 April 2010 Toggle the Widgetbar\n",
      "‚ò∞ * Login\r\n",
      " * Sign Up\r\n",
      "\r\n",
      " * Learning Paths\r\n",
      " * Courses * Our Courses\r\n",
      "    * Partner Courses\r\n",
      "   \r\n",
      "   \r\n",
      " * Badges * Our Badges\r\n",
      "    * BDU Badge Program\r\n",
      "   \r\n",
      "   \r\n",
      " * Watson Student Advisor\r\n",
      "\r\n",
      " * \r\n",
      "\r\n",
      "BLOG\r\n",
      "Welcome to the BDUBlog .SUBCRIBE VIA FEED\r\n",
      "RSS - Posts\r\n",
      "\r\n",
      "RSS - Comments\r\n",
      "\r\n",
      "SUBSCRIBE VIA EMAIL\r\n",
      "Enter your email address to subscribe to this blog and receive notifications of\r\n",
      "new posts by email.\r\n",
      "\r\n",
      "Email Address\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "RECENT POSTS\r\n",
      " * This Week in Data Science (April 18, 2017)\r\n",
      " * This Week in Data Science (April 11, 2017)\r\n",
      " * How to Become a Data Scientist\r\n",
      " * This Week in Data Science (April 4, 2017)\r\n",
      " * This Week in Data Science (March 28, 2017)\r\n",
      "\r\n",
      "CONNECT ON FACEBOOK\r\n",
      "Connect on FacebookFOLLOW US ON TWITTER\r\n",
      "My TweetsBLOGROLL\r\n",
      " * RBloggers\r\n",
      "\r\n",
      "THIS WEEK IN DATA SCIENCE (APRIL 18, 2017)\r\n",
      "Posted on April 18, 2017 by Janice Darling\r\n",
      "\r\n",
      "Here‚Äôs this week‚Äôs news in Data Science and Big Data.\r\n",
      "\r\n",
      "Don‚Äôt forget to subscribe if you find this useful!\r\n",
      "\r\n",
      "INTERESTING DATA SCIENCE ARTICLES AND NEWS\r\n",
      " * Top mistakes data scientists make when dealing with business people ‚Äì A discussion of the three top mistakes data scientists make.\r\n",
      " * 4 Trends in Artificial Intelligence that affect enterprises. ‚Äì Four AI trends that stand out in their affect on companies and\r\n",
      "   enterprises.\r\n",
      " * R Best Practices: R you writing the R way! ‚Äì A list of programming practices that result in improved readability,\r\n",
      "   consistency, and repeatability.\r\n",
      " * The 5 Best Reasons To Choose MYSQL ‚Äì and its 5 Biggest Challenges ‚Äì Reasons to use MYSQL and the common challenges associated.\r\n",
      " * 7 types of job profiles that make you a Data Scientist ‚Äì A discussion of the common skill sets of different data scientist\r\n",
      "   profiles.\r\n",
      " * Detecting Hackers & Impersonators with Machine Learning ‚Äì Applying Machine Learning to faster detect phishing attacks.\r\n",
      " * Some Lesser-Known Deep Learning Libraries ‚Äì A list of lesser known but useful Deep Learning libraries.\r\n",
      " * In case you missed it: March 2017 roundup ‚Äì Articles about R programming from Revolutions.\r\n",
      " * Investing, Fast & Slow ‚Äì Part 2: Investment for Data Scientists 101 ‚Äì Second part in a discussion series on investing and data science from\r\n",
      "   Dataconomy.\r\n",
      " * 10 Free Must-Read Books for Machine Learning and Data Science ‚Äì A list of interesting Machine Learning and Data Science reads.\r\n",
      " * Integrate Sparkr And R For Better Data Science Workflow ‚Äì How to work with R and Sparkr for wrangling with large datasets.\r\n",
      " * Can Watson, the Jeopardy champion, solve Parkinson‚Äôs? ‚Äì Toronto Researchers are using Watson to help find a cure for Parkinson‚Äôs.\r\n",
      " * The Henry Ford to debut ‚Äòcognitive dress‚Äô using IBM Watson technology ‚Äì The Henry Ford will display a dress created from a collaboration between\r\n",
      "   Marchesa and IBM Watson.\r\n",
      " * The Democratization of Machine Learning: What It Means for Tech Innovation ‚Äì How accessible ML can further spur tech innovation.\r\n",
      " * 3 reasons why data scientist remains the top job in America ‚Äì A discussion of why the role of data scientist has remained the top job in\r\n",
      "   America.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "FEATURED COURSES FROM BDU\r\n",
      " * SQL and Relational Databases 101 ‚Äì Learn the basics of the database querying language, SQL.\r\n",
      " * Big Data 101 ‚Äì What Is Big Data? Take Our Free Big Data Course to Find Out.\r\n",
      " * Predictive Modeling Fundamentals I ‚Äì Take this free course and learn the different mathematical algorithms used\r\n",
      "   to detect patterns hidden in data.\r\n",
      " * Using R with Databases ‚Äì Learn how to unleash the power of R when working with relational databases\r\n",
      "   in our newest free course.\r\n",
      " * Deep Learning with TensorFlow ‚Äì Take this free TensorFlow course and learn how to use Google‚Äôs library to\r\n",
      "   apply deep learning to different data types in order to solve real world\r\n",
      "   problems.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "UPCOMING DATA SCIENCE EVENTS\r\n",
      " * Data Science: Classification Algorithms in Python(Hands-On) ‚ÄìApril 25, 2017 @ 6 ‚Äì 8:30 pm Lighthouse Labs\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "COOL DATA SCIENCE VIDEOS\r\n",
      " * Machine Learning With Python ‚Äì Unsupervised Learning ‚Äì Measuring the\r\n",
      "   Distances Between Clusters ‚Äì Using Single Linkage Clustering to measure the distance between Clusters.\r\n",
      " * Machine Learning With Python ‚Äì Hierarchical Clustering Advantages &\r\n",
      "   Disadvantages ‚Äì A discussion of Hierarchical Clustering.\r\n",
      " * Machine Learning With Python ‚Äì Unsupervised Learning K Means Clustering\r\n",
      "   Advantages & Disadvantages ‚Äì A discussion of K-Means Clustering.\r\n",
      "\r\n",
      "SHARE THIS:\r\n",
      " * Facebook\r\n",
      " * Twitter\r\n",
      " * LinkedIn\r\n",
      " * Google\r\n",
      " * Pocket\r\n",
      " * Reddit\r\n",
      " * Email\r\n",
      " * Print\r\n",
      " * \r\n",
      "\r\n",
      "RELATED\r\n",
      "Tags: Big Data , data science , weekly roundup\r\n",
      "\r\n",
      "\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "\r\n",
      "COMMENTS\r\n",
      "LEAVE A REPLY CANCEL REPLY\r\n",
      " * About\r\n",
      " * Contact\r\n",
      " * Blog\r\n",
      " * Events\r\n",
      " * Ambassador Program\r\n",
      " * Resources\r\n",
      " * FAQ\r\n",
      " * Legal\r\n",
      "\r\n",
      "Follow us * \r\n",
      " * \r\n",
      " * \r\n",
      " * \r\n",
      " * \r\n",
      "\r\n",
      " * \r\n",
      " * \r\n",
      "\r\n",
      "Send to Email Address Your Name Your Email Address Cancel Post was not sent - check your email addresses! Email check failed, please try again Sorry, your blog cannot share posts by email.\n"
     ]
    }
   ],
   "source": [
    "for text in df_content['doc_body'][:3]:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Altough `doc_body` has by far the richest content, it would need lots of cleaning to be properly prepared for NLP and used for content based recommendations. This is beyond the scope of this project. We will use the `doc_description`instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP with TFIDF-Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(message):\n",
    "    \"\"\"Tokenization function to process text data. \"\"\"\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    # normalize case and remove punctuation\n",
    "    message = re.sub(r\"[^a-zA-Z0-9]\", \" \", message.lower())\n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(message)\n",
    "    # lemmatize, stip and remove stop words\n",
    "    tokens = [lemmatizer.lemmatize(word.strip()) for word in tokens if word not in stop_words]\n",
    "    # add part-of-speech tags\n",
    "    tokens = pos_tag(tokens)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect bad readings in real time using Python and Streaming Analytics.\n",
      "[('detect', 'JJ'), ('bad', 'JJ'), ('reading', 'VBG'), ('real', 'JJ'), ('time', 'NN'), ('using', 'VBG'), ('python', 'JJ'), ('streaming', 'VBG'), ('analytics', 'NNS')] \n",
      "\n",
      "See the forest, see the trees. Here lies the challenge in both performing and presenting an analysis. As data scientists, analysts, and machine learning engineers faced with fulfilling business obj‚Ä¶\n",
      "[('see', 'VB'), ('forest', 'JJS'), ('see', 'VB'), ('tree', 'JJ'), ('lie', 'NN'), ('challenge', 'NN'), ('performing', 'VBG'), ('presenting', 'VBG'), ('analysis', 'NN'), ('data', 'NNS'), ('scientist', 'NN'), ('analyst', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('engineer', 'NN'), ('faced', 'VBD'), ('fulfilling', 'VBG'), ('business', 'NN'), ('obj', 'NN')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check function\n",
    "\n",
    "for description in df_content['doc_description'][:2]:\n",
    "    tokens = tokenize_text(description)\n",
    "    print(description)\n",
    "    print(tokens, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for TF-IDF-Vectorizing\n",
    "\n",
    "def apply_TfidfVectorizing(corpus):\n",
    "    # initialize tf-idf vectorizer object\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenize_text)\n",
    "    # compute bag of word counts and tf-idf values\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "#     # convert sparse matrix to numpy array to view\n",
    "#     X.toarray()\n",
    "    \n",
    "    return X, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 118)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function\n",
    "\n",
    "corpus = df_content['doc_description'][:10]\n",
    "X, vectorizer = apply_TfidfVectorizing(corpus)\n",
    "\n",
    "# check result\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.25622513,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.20503742]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('4', 'CD'), ('5', 'CD'), ('9', 'CD'), ('analysis', 'NN'), ('analyst', 'NN'), ('analytics', 'NNS'), ('apache', 'NN'), ('appears', 'VBZ'), ('bad', 'JJ'), ('become', 'NN'), ('big', 'JJ'), ('bound', 'IN'), ('browser', 'NN'), ('build', 'VB'), ('business', 'NN'), ('career', 'NN'), ('challenge', 'NN'), ('class', 'NN'), ('collaborate', 'NN'), ('company', 'NN'), ('compete', 'JJ'), ('compose', 'JJ'), ('console', 'NN'), ('data', 'NNS'), ('datascience', 'NN'), ('db', 'JJ'), ('demonstrates', 'VBZ'), ('deployment', 'JJ'), ('detect', 'JJ'), ('distributed', 'VBD'), ('driven', 'RB'), ('ecosystem', 'NN'), ('engineer', 'NN'), ('engineering', 'NN'), ('essential', 'JJ'), ('experience', 'NN'), ('faced', 'VBD'), ('fang', 'NN'), ('forest', 'JJS'), ('fulfilling', 'VBG'), ('home', 'NN'), ('ibm', 'JJ'), ('increase', 'NN'), ('inspection', 'NN'), ('interesting', 'JJ'), ('introduce', 'NN'), ('kaggle', 'NN'), ('latency', 'NN'), ('learn', 'NN'), ('learn', 'VBP'), ('learning', 'NN'), ('learning', 'VBG'), ('lie', 'NN'), ('like', 'IN'), ('machine', 'NN'), ('major', 'JJ'), ('new', 'JJ'), ('news', 'NN'), ('obj', 'NN'), ('perform', 'NN'), ('performing', 'VBG'), ('persistent', 'JJ'), ('podcast', 'JJ'), ('possible', 'JJ'), ('post', 'NN'), ('postgresql', 'JJ'), ('postgresql', 'NN'), ('postgresql', 'NNS'), ('power', 'NN'), ('presenting', 'VBG'), ('problem', 'NN'), ('process', 'NN'), ('product', 'NN'), ('provide', 'VBP'), ('python', 'JJ'), ('radar', 'VBN'), ('reading', 'VBG'), ('real', 'JJ'), ('reilly', 'RB'), ('reliably', 'RB'), ('restaurant', 'JJ'), ('safely', 'RB'), ('scaling', 'VBG'), ('scenario', 'NN'), ('science', 'NN'), ('scientist', 'NN'), ('security', 'NN'), ('see', 'VB'), ('show', 'VBP'), ('simple', 'JJ'), ('size', 'NN'), ('skill', 'NN'), ('slack', 'NN'), ('solve', 'NN'), ('spark', 'NN'), ('state', 'NN'), ('storage', 'NN'), ('streaming', 'VBG'), ('strives', 'NNS'), ('subscribe', 'NN'), ('team', 'NN'), ('time', 'NN'), ('tree', 'JJ'), ('understanding', 'VBG'), ('unsupervised', 'VBD'), ('upgrade', 'NN'), ('upgrading', 'VBG'), ('use', 'NN'), ('user', 'NN'), ('using', 'VBG'), ('version', 'NN'), ('video', 'NN'), ('week', 'NN'), ('work', 'NN'), ('working', 'VBG'), ('world', 'NN'), ('york', 'NN'), ('yu', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# explore\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        ,  0.        ,  0.05152734,\n",
       "         0.1014903 ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.04329467,  0.01197067,  0.01228819,\n",
       "         0.02420331,  0.        ,  0.02042251,  0.1502582 ,  0.05241081],\n",
       "       [ 0.        ,  0.04329467,  1.        ,  0.05020093,  0.05153251,\n",
       "         0.1015005 ,  0.        ,  0.08564509,  0.1649513 ,  0.13199794],\n",
       "       [ 0.        ,  0.01197067,  0.05020093,  1.        ,  0.01424837,\n",
       "         0.02806417,  0.        ,  0.02368026,  0.02680074,  0.02144658],\n",
       "       [ 0.05152734,  0.01228819,  0.05153251,  0.01424837,  1.        ,\n",
       "         0.10967299,  0.        ,  0.02430838,  0.07795722,  0.02201545],\n",
       "       [ 0.1014903 ,  0.02420331,  0.1015005 ,  0.02806417,  0.10967299,\n",
       "         1.        ,  0.06617805,  0.04787875,  0.05418799,  0.04336252],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.06617805,  1.        ,  0.02792018,  0.        ,  0.05057314],\n",
       "       [ 0.        ,  0.02042251,  0.08564509,  0.02368026,  0.02430838,\n",
       "         0.04787875,  0.02792018,  1.        ,  0.04572328,  0.03658885],\n",
       "       [ 0.        ,  0.1502582 ,  0.1649513 ,  0.02680074,  0.07795722,\n",
       "         0.05418799,  0.        ,  0.04572328,  1.        ,  0.07046964],\n",
       "       [ 0.        ,  0.05241081,  0.13199794,  0.02144658,  0.02201545,\n",
       "         0.04336252,  0.05057314,  0.03658885,  0.07046964,  1.        ]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the cosine similarity matrix\n",
    "\n",
    "cosine_sim = cosine_similarity(X, X)\n",
    "\n",
    "# check\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update function to return the similarity_matrix\n",
    "\n",
    "def create_similarity_matrix(corpus):\n",
    "     \n",
    "    # initialize tf-idf vectorizer object\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenize_text)\n",
    "    # compute bag of word counts and tf-idf values\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    # create cosine similarity_matrix\n",
    "    sim_matrix = cosine_similarity(X, X)\n",
    "    \n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN in description column with full title\n",
    "\n",
    "df_content['doc_description'].fillna(value=df_content['doc_full_name'], inplace=True)\n",
    "\n",
    "matrix = create_similarity_matrix(df_content['doc_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056, 1056)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
