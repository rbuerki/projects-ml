{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\r2d4\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\r2d4\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\r2d4\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\r2d4\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\r2d4\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\r2d4\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'stopwords', 'averaged_perceptron_tagger', 'maxent_ne_chunker', 'words'])\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(); color='rebeccapurple'\n",
    "%matplotlib inline  \n",
    "\n",
    "# display settings\n",
    "pd.set_option('max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database with `read_sql_table`\n",
    "engine = create_engine('sqlite:///DisasterResponse.db')\n",
    "df = pd.read_sql_table('messages', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25992 entries, 0 to 25991\n",
      "Data columns (total 39 columns):\n",
      "id                        25992 non-null int64\n",
      "message                   25992 non-null object\n",
      "original                  10021 non-null object\n",
      "genre                     25992 non-null object\n",
      "related                   25992 non-null int64\n",
      "request                   25992 non-null int64\n",
      "offer                     25992 non-null int64\n",
      "aid_related               25992 non-null int64\n",
      "medical_help              25992 non-null int64\n",
      "medical_products          25992 non-null int64\n",
      "search_and_rescue         25992 non-null int64\n",
      "security                  25992 non-null int64\n",
      "military                  25992 non-null int64\n",
      "water                     25992 non-null int64\n",
      "food                      25992 non-null int64\n",
      "shelter                   25992 non-null int64\n",
      "clothing                  25992 non-null int64\n",
      "money                     25992 non-null int64\n",
      "missing_people            25992 non-null int64\n",
      "refugees                  25992 non-null int64\n",
      "death                     25992 non-null int64\n",
      "other_aid                 25992 non-null int64\n",
      "infrastructure_related    25992 non-null int64\n",
      "transport                 25992 non-null int64\n",
      "buildings                 25992 non-null int64\n",
      "electricity               25992 non-null int64\n",
      "tools                     25992 non-null int64\n",
      "hospitals                 25992 non-null int64\n",
      "shops                     25992 non-null int64\n",
      "aid_centers               25992 non-null int64\n",
      "other_infrastructure      25992 non-null int64\n",
      "weather_related           25992 non-null int64\n",
      "floods                    25992 non-null int64\n",
      "storm                     25992 non-null int64\n",
      "fire                      25992 non-null int64\n",
      "earthquake                25992 non-null int64\n",
      "cold                      25992 non-null int64\n",
      "other_weather             25992 non-null int64\n",
      "direct_report             25992 non-null int64\n",
      "dtypes: int64(36), object(3)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets (with stratified sampling)\n",
    "After EDA (documented in separate `EDA.ipynb`) the decision was taken to use stratfied sampling for splitting into training and test set. The proportion of the different _numbers of active categories per message_ will be preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with total number of active categories per message\n",
    "df['total'] = df.iloc[:,4:40].sum(axis=1)\n",
    "# for StratifiedShuffleSlpit to work properly all values > 10 in ['total'] column will be set to 11. (Kind of oultier removal.)\n",
    "df['total'] = np.where((df['total'] >10), 11, df['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testset with stratified sampling according to the category count per message\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 111)\n",
    "for train_index, test_index in split.split(df, df['total']):\n",
    "    train = df.loc[train_index]\n",
    "    test = df.loc[test_index]\n",
    "    \n",
    "# safety-check\n",
    "assert np.abs(len(test) - (len(df) * 0.2)) <= 1, 'split got messed up'\n",
    "assert (round(df['related'].sum() / len(df),3)) == (round(train['related'].sum() / len(train),3)), 'not properly stratisfied'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'total' column from train and test sets\n",
    "for set_ in (train, test):\n",
    "    set_.drop('total', axis=1, inplace=True)\n",
    "    \n",
    "# safety-check\n",
    "assert len(test.columns) == 39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into features an target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['message'].values\n",
    "Y_train = train.iloc[:, 4:39].values\n",
    "\n",
    "X_test = test['message'].values\n",
    "Y_test = test.iloc[:, 4:39].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Some 2,000 women protesting against the conduct of the elections were teargassed as they tried to converge on the local electoral commission offices in the southern oil city of Port Harcourt.',\n",
       "       'Good evening to all USA soldiers. we still suffer from this great event. We would love to handle your presence of authority. thank you'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "Y_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(message):\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    # normalize case and remove punctuation\n",
    "    message = re.sub(r\"[^a-zA-Z0-9]\", \" \", message.lower())\n",
    "    # tokenize text\n",
    "    tokens = word_tokenize(message)\n",
    "    # lemmatize and remove stop words\n",
    "    tokens = [lemmatizer.lemmatize(word.strip()) for word in tokens if word not in stop_words]\n",
    "    # add part-of-speech tags\n",
    "    tokens = pos_tag(tokens)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some 2,000 women protesting against the conduct of the elections were teargassed as they tried to converge on the local electoral commission offices in the southern oil city of Port Harcourt.\n",
      "[('2', 'CD'), ('000', 'CD'), ('woman', 'NN'), ('protesting', 'VBG'), ('conduct', 'NN'), ('election', 'NN'), ('teargassed', 'VBD'), ('tried', 'JJ'), ('converge', 'NN'), ('local', 'JJ'), ('electoral', 'JJ'), ('commission', 'NN'), ('office', 'NN'), ('southern', 'JJ'), ('oil', 'NN'), ('city', 'NN'), ('port', 'NN'), ('harcourt', 'NN')] \n",
      "\n",
      "Good evening to all USA soldiers. we still suffer from this great event. We would love to handle your presence of authority. thank you\n",
      "[('good', 'JJ'), ('evening', 'NN'), ('usa', 'NN'), ('soldier', 'NN'), ('still', 'RB'), ('suffer', 'VBZ'), ('great', 'JJ'), ('event', 'NN'), ('would', 'MD'), ('love', 'VB'), ('handle', 'VB'), ('presence', 'NN'), ('authority', 'NN'), ('thank', 'NN')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "for message in X_train[:2]:\n",
    "    tokens = tokenize_text(message)\n",
    "    print(message)\n",
    "    print(tokens, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "Use sk-learn's [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) ([example here](https://scikit-learn.org/stable/modules/multiclass.html#multioutput-classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 323.91256976127625 seconds\n"
     ]
    }
   ],
   "source": [
    "# define the classifier, wrapped in MultiOutputClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=-1)\n",
    "\n",
    "# build the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize_text)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(clf, n_jobs=-1)),\n",
    "              ])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# train the pipeline\n",
    "model = pipe.fit(X_train, Y_train)\n",
    "# predict labels on test_set\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "print('Duration: {} seconds'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multilabel(Y-test, Y-pred):\n",
    "    \"\"\"Calculate evaluation metrics for ML model\n",
    "    \n",
    "    ARGUMENTS:\n",
    "    Y-test: Array containing actual labels.\n",
    "    Y-pred: Array containing predicted labels.\n",
    "       \n",
    "    RETURNS:\n",
    "    metrics_df: Dataframe containing the accuracy, precision, \n",
    "    recall and f1 scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # create list of strings with target class names\n",
    "    target_names = train.iloc[:, (-1 * Y-train.shape[1]):].columns\n",
    "    \n",
    "    \n",
    "    # Calculate evaluation metrics for each set of labels\n",
    "    metrics = []\n",
    "    for i in range(len(target_names)):\n",
    "        accuracy = accuracY-score(Y-test[:, i], Y-pred[:, i])\n",
    "        f1 = f1_score(Y-test[:, i], Y-pred[:, i], average='macro')  # not taking imbalance into account\n",
    "        precision = precision_score(Y-test[:, i], Y-pred[:, i], average='macro')\n",
    "        recall = recall_score(Y-test[:, i], Y-pred[:, i], average='macro')\n",
    "\n",
    "        metrics.append([accuracy, f1, precision, recall])\n",
    "    \n",
    "    # Create dataframe containing metrics\n",
    "    metrics = np.array(metrics)\n",
    "    metrics_df = pd.DataFrame(\n",
    "        data = metrics, index = target_names, \n",
    "        columns = ['Accuracy', 'F1', 'Precision', 'Recall'],\n",
    "        )\n",
    "      \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multilabel(Y_real, Y_pred):\n",
    "    \"\"\"Calculate evaluation metrics for ML model\n",
    "    \n",
    "    ARGUMENTS:\n",
    "    Y_real: Array containing actual labels.\n",
    "    Y_pred: Array containing predicted labels.\n",
    "       \n",
    "    RETURNS:\n",
    "    metrics_df: Dataframe containing the multilabel\n",
    "    classification report.\n",
    "    \"\"\"\n",
    "    \n",
    "    # create list of strings with target class names\n",
    "    target_names = train.iloc[:, (-1 * Y_train.shape[1]):].columns\n",
    "    \n",
    "    # Calculate classification report\n",
    "    metrics = classification_report(\n",
    "                Y_real, Y_pred,\n",
    "                target_names=target_names,\n",
    "                output_dict=True,\n",
    "                )\n",
    "\n",
    "    # Create dataframe, tanspose it\n",
    "    metrics_df = pd.DataFrame(\n",
    "                    data = metrics, \n",
    "                    ).T\n",
    "      \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r2d4\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\r2d4\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\r2d4\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.889883</td>\n",
       "      <td>0.836766</td>\n",
       "      <td>0.950201</td>\n",
       "      <td>3976.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.603854</td>\n",
       "      <td>0.816602</td>\n",
       "      <td>0.479049</td>\n",
       "      <td>883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.695568</td>\n",
       "      <td>0.731880</td>\n",
       "      <td>0.662689</td>\n",
       "      <td>2179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.099602</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.053996</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.112211</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.023256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.139303</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.429561</td>\n",
       "      <td>0.853211</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.821883</td>\n",
       "      <td>0.595941</td>\n",
       "      <td>542.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.514638</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.367033</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.067227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.237762</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.138776</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.056911</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.029830</td>\n",
       "      <td>704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.006231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.123552</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.066946</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.216783</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.123016</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.741512</td>\n",
       "      <td>0.861883</td>\n",
       "      <td>0.650643</td>\n",
       "      <td>1477.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.596376</td>\n",
       "      <td>0.928205</td>\n",
       "      <td>0.439320</td>\n",
       "      <td>412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.589839</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.470356</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.031250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.829569</td>\n",
       "      <td>0.884026</td>\n",
       "      <td>0.781431</td>\n",
       "      <td>517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.072993</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.787589</td>\n",
       "      <td>0.335025</td>\n",
       "      <td>985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.632451</td>\n",
       "      <td>0.816576</td>\n",
       "      <td>0.516082</td>\n",
       "      <td>16571.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.252248</td>\n",
       "      <td>0.679838</td>\n",
       "      <td>0.199917</td>\n",
       "      <td>16571.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.558103</td>\n",
       "      <td>0.788134</td>\n",
       "      <td>0.516082</td>\n",
       "      <td>16571.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.505402</td>\n",
       "      <td>0.668145</td>\n",
       "      <td>0.474040</td>\n",
       "      <td>16571.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        f1-score  precision    recall  support\n",
       "related                 0.889883  0.836766   0.950201  3976.0 \n",
       "request                 0.603854  0.816602   0.479049  883.0  \n",
       "offer                   0.000000  0.000000   0.000000  32.0   \n",
       "aid_related             0.695568  0.731880   0.662689  2179.0 \n",
       "medical_help            0.099602  0.641026   0.053996  463.0  \n",
       "medical_products        0.112211  0.894737   0.059859  284.0  \n",
       "search_and_rescue       0.119048  0.769231   0.064516  155.0  \n",
       "security                0.023256  1.000000   0.011765  85.0   \n",
       "military                0.139303  0.700000   0.077348  181.0  \n",
       "water                   0.429561  0.853211   0.287037  324.0  \n",
       "food                    0.690909  0.821883   0.595941  542.0  \n",
       "shelter                 0.514638  0.860825   0.367033  455.0  \n",
       "clothing                0.164706  0.583333   0.095890  73.0   \n",
       "money                   0.067227  1.000000   0.034783  115.0  \n",
       "missing_people          0.058824  1.000000   0.030303  66.0   \n",
       "refugees                0.022989  0.333333   0.011905  168.0  \n",
       "death                   0.237762  0.829268   0.138776  245.0  \n",
       "other_aid               0.056911  0.617647   0.029830  704.0  \n",
       "infrastructure_related  0.006231  1.000000   0.003125  320.0  \n",
       "transport               0.123552  0.800000   0.066946  239.0  \n",
       "buildings               0.216783  0.911765   0.123016  252.0  \n",
       "electricity             0.064516  0.666667   0.033898  118.0  \n",
       "tools                   0.000000  0.000000   0.000000  29.0   \n",
       "hospitals               0.000000  0.000000   0.000000  67.0   \n",
       "shops                   0.000000  0.000000   0.000000  28.0   \n",
       "aid_centers             0.000000  0.000000   0.000000  59.0   \n",
       "other_infrastructure    0.009709  0.500000   0.004902  204.0  \n",
       "weather_related         0.741512  0.861883   0.650643  1477.0 \n",
       "floods                  0.596376  0.928205   0.439320  412.0  \n",
       "storm                   0.589839  0.790698   0.470356  506.0  \n",
       "fire                    0.031250  1.000000   0.015873  63.0   \n",
       "earthquake              0.829569  0.884026   0.781431  517.0  \n",
       "cold                    0.150000  0.818182   0.082569  109.0  \n",
       "other_weather           0.072993  0.555556   0.039062  256.0  \n",
       "direct_report           0.470085  0.787589   0.335025  985.0  \n",
       "micro avg               0.632451  0.816576   0.516082  16571.0\n",
       "macro avg               0.252248  0.679838   0.199917  16571.0\n",
       "weighted avg            0.558103  0.788134   0.516082  16571.0\n",
       "samples avg             0.505402  0.668145   0.474040  16571.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_multilabel(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-ebfcaa0478ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate_multilabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_multilabel(Y_train, Y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different baseline models\n",
    "\n",
    "Evaluation of different possible classifiers, Validation with stratified k-fold CV. Models are:\n",
    "- LogisticRegression \n",
    "- GaussianNB (Na√Øve Bayes) \n",
    "- KNeighborsClassifier \n",
    "- SVC \n",
    "- RandomForestClassifier \n",
    "- XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize baseline models in list\n",
    "classifiers = [\n",
    "    LogisticRegression(solver='liblinear'),\n",
    "    KNeighborsClassifier(3), \n",
    "    SVC(gamma='auto'), \n",
    "    GaussianNB(),\n",
    "    RandomForestClassifier(n_estimators=10),\n",
    "    GradientBoostingClassifier(n_estimators=100),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-46-07bfbc61efdd>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-46-07bfbc61efdd>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    def evaluate_baseline_models(model_list, X_train, y_train, cv=StratifiedKFold(3), scorer)\u001b[0m\n\u001b[1;37m                                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# for each model, fit to train set and validate with stratified 3-fold CV, store results in nested dict\n",
    "\n",
    "def evaluate_baseline_models(model_list, X_train, y_train, cv=StratifiedKFold(3), scorer):\n",
    "    \"\"\"This Funciont is built on top of sk-learn's cross_validate function. \n",
    "       It fits baseline models to train set and validates results with CV.\n",
    "       \n",
    "       ARGUMENTS:\n",
    "       model_list: list of sk-learn model objects\n",
    "       X_train: training features (df or array)\n",
    "       y_train: training labels (df or array)\n",
    "       cv: type of CV, default is StratifiedKFold(3)\n",
    "       scorer: evaluation metric for validation\n",
    "       \n",
    "       RETURNS:\n",
    "       baseline_results: dataframe with\n",
    "\"\"\"\n",
    "    # store results of cross_validate in nested dict\n",
    "    baseline_results = {}\n",
    "    \n",
    "    for clf in tqdm(model_list):\n",
    "    try:  # standard type for data input is df\n",
    "        clfName = clf.__class__.__name__\n",
    "        scores = cross_validate(\n",
    "            clf, X_train, y_train, cv=cv, error_score='raise', \n",
    "            n_jobs=-1, scoring=scorer, return_train_score=False, \n",
    "            return_estimator=True\n",
    "        )\n",
    "    except:  # exception for classifiers that need data as array\n",
    "        clfName = clf.__class__.__name__ \n",
    "        scores = cross_validate(\n",
    "            clf, X_train.toarray(), y_train, cv=cv, \n",
    "            error_score='raise', n_jobs=-1,\n",
    "            scoring=scorer, return_train_score=False, \n",
    "            return_estimator=True\n",
    "        )\n",
    "        \n",
    "    baseline_results[clfName] = scores\n",
    "    \n",
    "    # create dataframe with extra metrics (95_conf, total_time)\n",
    "    baseline_results = pd.DataFrame(baseline_results).T\n",
    "    baseline_results['95_conf'] = \\\n",
    "        baseline_results['test_score'].apply(lambda x: np.std(x) * 2)\n",
    "    for col in df.iloc[:,1:]:\n",
    "        df[col] = df[col].apply(lambda x: np.mean(x))\n",
    "    df['total_time'] = df['score_time'] + df['fit_time']\n",
    "    df.columns = ['estimator, test_score', '95_conf', \n",
    "                  'total_time', 'fit_time', 'score_time']\n",
    "    baseline_results = df\n",
    "    \n",
    "    return basline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    \n",
    "    \n",
    "    df.columns = ['estimator, test_score', '95_conf', 'total_time', 'fit_time', 'score_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-84949413bfaa>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-84949413bfaa>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    parameters =\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "parameters = \n",
    "\n",
    "cv = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = list(train.iloc[:, (-1 * y_train.shape[1]):].columns)\n",
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fun evaluate: set columns in col_names to right\n",
    "\n",
    "- to do: concatenate one hot encoded genre with text\n",
    "- eventually length and total categories to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
