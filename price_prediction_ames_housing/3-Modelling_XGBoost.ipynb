{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with XGBoost\n",
    "\n",
    "Modelling wiht XGBoost. First I have evaluated different feature set configurations (but not as in detail as in nb 2). The basic pre-processing scores best, as expected log-transformation and scaling has a negative impact on this algorithm. But probably I should have to have tuned some more as the r2-score on the test set is a bit worse than for ElasticNet!\n",
    "\n",
    "**Data Sources**\n",
    "- `data/raw/train.csv`: Training set from kaggle.\n",
    "- `data/interim/train_opti_EN` / `data/interim/y_train_EN`: Preprocessed training data (optimized for EN).\n",
    "\n",
    "**Output**\n",
    "- `data/interim/features_XGB` / `data/interim/features_XGB`: Preprocessed data (best suited for XGB).\n",
    "- `models/XGB_final.pkl'`: Final model.\n",
    "\n",
    "**Changes**\n",
    "- 2019-04-11: Start and finish notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-libraries,-load-data\" data-toc-modified-id=\"Import-libraries,-load-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import libraries, load data</a></span></li><li><span><a href=\"#Evaluate-on-different-feature-set-configurations\" data-toc-modified-id=\"Evaluate-on-different-feature-set-configurations-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Evaluate on different feature set configurations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Unprocessed-Data\" data-toc-modified-id=\"Unprocessed-Data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Unprocessed Data</a></span></li><li><span><a href=\"#Data-with-basic-pre-processing\" data-toc-modified-id=\"Data-with-basic-pre-processing-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Data with basic pre-processing</a></span></li><li><span><a href=\"#Final-features-optimized-for-EN\" data-toc-modified-id=\"Final-features-optimized-for-EN-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Final features optimized for EN</a></span></li></ul></li><li><span><a href=\"#Final-tuning-&amp;-evaluation\" data-toc-modified-id=\"Final-tuning-&amp;-evaluation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Final tuning &amp; evaluation</a></span></li><li><span><a href=\"#Save-final-data-and-model\" data-toc-modified-id=\"Save-final-data-and-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Save final data and model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:10.378420Z",
     "start_time": "2019-04-13T14:05:08.133932Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# My functions\n",
    "import EDA_functions as EDA\n",
    "import cleaning_functions as cleaning\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #, sns.set_style('whitegrid')\n",
    "color = 'rebeccapurple'\n",
    "%matplotlib inline\n",
    "\n",
    "# Display settings\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:10.548282Z",
     "start_time": "2019-04-13T14:05:10.382642Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = pd.read_csv('data/raw/train.csv')\n",
    "EN_train = pd.read_csv('data/interim/train_opti_EN')\n",
    "EN_labels = pd.read_csv('data/interim/y_train_EN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:10.580466Z",
     "start_time": "2019-04-13T14:05:10.552722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load variables from notebook 1\n",
    "%store -r cols_to_del\n",
    "%store -r cols_to_log\n",
    "%store -r outliers_to_del\n",
    "%store -r top_corr_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on different feature set configurations\n",
    "Use default XGB model.\n",
    "\n",
    "### Unprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:10.821629Z",
     "start_time": "2019-04-13T14:05:10.596212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split features and target variable\n",
    "X_temp = raw_data.drop(['SalePrice'], axis = 1)\n",
    "y = raw_data['SalePrice'].copy()\n",
    "# One-Hot-Encode features and save column names\n",
    "X = pd.get_dummies(X_temp, dummy_na=True)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size = 0.2, random_state = 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:22.971318Z",
     "start_time": "2019-04-13T14:05:10.833249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-Score: 85.64% (5.46%)\n"
     ]
    }
   ],
   "source": [
    "# Evalualte on unprocessed data\n",
    "model = XGBRegressor() \n",
    "kfold = KFold(n_splits=5, random_state=7) \n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='r2') \n",
    "print(\"R2-Score: {0:.2f}% ({1:.2f}%)\".format(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T20:48:57.218638Z",
     "start_time": "2019-03-25T20:48:57.214648Z"
    }
   },
   "source": [
    "### Data with basic pre-processing \n",
    "\n",
    "Same steps as in notebook 2, before pipeline tuning - but without log-scaling. (**Note:** Log-scaling has a significant negative impact, I checked that.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:23.222016Z",
     "start_time": "2019-04-13T14:05:22.974677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MiscFeature successfully deleted'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'PoolQC successfully deleted'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'FireplaceQu successfully deleted'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Alley successfully deleted'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Id successfully deleted'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Fence successfully deleted'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Disable warning\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# Create and clean training set with variables from the EDA notebook\n",
    "train_data = (raw_data\n",
    "              .pipe(cleaning.change_dtypes, cols_to_category=raw_data.select_dtypes(object))\n",
    "              .pipe(cleaning.delete_columns, cols_to_delete=cols_to_del)\n",
    "#               .pipe(cleaning.apply_log, cols_to_transform=cols_to_log) \n",
    "             )\n",
    "\n",
    "train_data.drop(outliers_to_del, inplace=True)\n",
    "train_data.dropna(subset=['MasVnrArea', 'MasVnrType', 'Electrical'], inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:23.240087Z",
     "start_time": "2019-04-13T14:05:23.225747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1447, 75)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check results\n",
    "display(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:23.396039Z",
     "start_time": "2019-04-13T14:05:23.242443Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split features and target variable\n",
    "X_temp = train_data.drop(['SalePrice'], axis = 1)\n",
    "y = train_data['SalePrice'].copy()\n",
    "# One-Hot-Encode features and save column names\n",
    "X = pd.get_dummies(X_temp, dummy_na=True)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size = 0.2, random_state = 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:34.853384Z",
     "start_time": "2019-04-13T14:05:23.400119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-Score: 91.04% (1.40%)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='r2') \n",
    "print(\"R2-Score: {0:.2f}% ({1:.2f}%)\".format(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T14:15:54.586342Z",
     "start_time": "2019-04-11T14:15:54.582296Z"
    }
   },
   "source": [
    "### Final features optimized for EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:34.899647Z",
     "start_time": "2019-04-13T14:05:34.856873Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(EN_train, EN_labels, test_size = 0.2, random_state = 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:42.930498Z",
     "start_time": "2019-04-13T14:05:34.904960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-Score: 87.89% (2.41%)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='r2') \n",
    "print(\"R2-Score: {0:.2f}% ({1:.2f}%)\".format(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Feature set with basic pre-processing ist best suited for this algorithm (probably I could even further tweak / reduce the performed steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T12:17:48.435226Z",
     "start_time": "2019-04-06T12:17:48.429610Z"
    }
   },
   "source": [
    "## Final tuning & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:43.097235Z",
     "start_time": "2019-04-13T14:05:42.932496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split features and target variable (repetition from above, I'm lazy)\n",
    "X_temp = train_data.drop(['SalePrice'], axis = 1)\n",
    "y = train_data['SalePrice'].copy()\n",
    "# One-Hot-Encode features and save column names\n",
    "X = pd.get_dummies(X_temp, dummy_na=True)\n",
    "feature_names_XGB = X.columns\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size = 0.2, random_state = 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:43.127690Z",
     "start_time": "2019-04-13T14:05:43.100690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond'], dtype='object')\n",
      "Number of one-hot-encoded features:  308\n"
     ]
    }
   ],
   "source": [
    "# Check feature_names\n",
    "print(feature_names_XGB[:5])\n",
    "print(\"Number of one-hot-encoded features: \", len(feature_names_XGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T12:27:57.171828Z",
     "start_time": "2019-04-06T12:27:57.156938Z"
    }
   },
   "source": [
    "Note: Numeric features are passed before categorical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T14:05:43.143551Z",
     "start_time": "2019-04-13T14:05:43.131872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1)\n"
     ]
    }
   ],
   "source": [
    "# Inspect baseline model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-13T14:05:08.203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tune model with gridsearch\n",
    "n_estimators = [300, 500, 700]\n",
    "learning_rate = [0.05, 0.08, 0.1]\n",
    "param_grid = {'n_estimators' : n_estimators, \n",
    "              'learning_rate' : learning_rate,\n",
    "             } \n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=666) \n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"r2\", n_jobs=-1, cv=kfold) \n",
    "grid_result = grid_search.fit(X_train, y_train) \n",
    "# Summarize results \n",
    "print(\"Best: {} using {}\".format(grid_result.best_score_, grid_result.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-13T14:05:08.210Z"
    }
   },
   "outputs": [],
   "source": [
    "means = grid_result.cv_results_['mean_test_score'] \n",
    "stds = grid_result.cv_results_['std_test_score'] \n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params): \n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-13T14:05:08.217Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot results \n",
    "scores = np.array(means).reshape(len(learning_rate), len(n_estimators)) \n",
    "for i, value in enumerate(learning_rate): \n",
    "    plt.plot(n_estimators, scores[i], label='learning_rate: ' + str(value)) \n",
    "    plt.legend() \n",
    "    plt.xlabel('n_estimators' )\n",
    "    plt.ylabel('r2 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-13T14:05:08.224Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize final model\n",
    "XGB_final = XGBRegressor(learning_rate=0.08, n_estimators=500)\n",
    "\n",
    "# Fit and predict (with early stopping)\n",
    "XGB_final.fit(X_train, y_train, \n",
    "              early_stopping_rounds=20, \n",
    "              eval_metric='rmse',\n",
    "              eval_set=[(X_test, y_test)], \n",
    "              verbose=False)\n",
    "\n",
    "y_train_pred = XGB_final.predict(X_train)\n",
    "y_pred = XGB_final.predict(X_test)\n",
    "\n",
    "# Output results\n",
    "print('Train r2 score: ', r2_score(y_train_pred, y_train))\n",
    "print('Test r2 score: ', r2_score(y_test, y_pred))\n",
    "\n",
    "train_mse = mean_squared_error(y_train_pred, y_train)\n",
    "test_mse = mean_squared_error(y_pred, y_test)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Train RMSE: %.4f' % train_rmse)\n",
    "print('Test RMSE: %.4f' % test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save final data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-13T14:05:08.232Z"
    }
   },
   "outputs": [],
   "source": [
    "X.to_csv('data/interim/features_XGB', index=False)\n",
    "y.to_csv('data/interim/labels_XGB', index=False)\n",
    "joblib.dump(XGB_final, 'models/XGB_final.pkl')\n",
    "%store feature_names_XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "464.86px",
    "left": "1092.86px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
