{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV, \\\n",
    "    cross_val_score, StratifiedKFold, validation_curve, learning_curve\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.metrics import make_scorer, classification_report, confusion_matrix, fbeta_score\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set; sns.set_style('whitegrid')\n",
    "%matplotlib inline  \n",
    "\n",
    "# display of all columns in df - check if pd option below isn't better\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = pd.read_csv('Financial Distress.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3670 entries, 0 to 3669\n",
      "Columns: 127 entries, Company to x124\n",
      "dtypes: float64(114), int64(13)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "XX.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Time</th>\n",
       "      <th>Financial Distress</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "      <th>x33</th>\n",
       "      <th>x34</th>\n",
       "      <th>x35</th>\n",
       "      <th>x36</th>\n",
       "      <th>x37</th>\n",
       "      <th>x38</th>\n",
       "      <th>x39</th>\n",
       "      <th>x40</th>\n",
       "      <th>x41</th>\n",
       "      <th>x42</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>x50</th>\n",
       "      <th>x51</th>\n",
       "      <th>x52</th>\n",
       "      <th>x53</th>\n",
       "      <th>x54</th>\n",
       "      <th>x55</th>\n",
       "      <th>x56</th>\n",
       "      <th>x57</th>\n",
       "      <th>x58</th>\n",
       "      <th>x59</th>\n",
       "      <th>x60</th>\n",
       "      <th>x61</th>\n",
       "      <th>x62</th>\n",
       "      <th>x63</th>\n",
       "      <th>x64</th>\n",
       "      <th>x65</th>\n",
       "      <th>x66</th>\n",
       "      <th>x67</th>\n",
       "      <th>x68</th>\n",
       "      <th>x69</th>\n",
       "      <th>x70</th>\n",
       "      <th>x71</th>\n",
       "      <th>x72</th>\n",
       "      <th>x73</th>\n",
       "      <th>x74</th>\n",
       "      <th>x75</th>\n",
       "      <th>x76</th>\n",
       "      <th>x77</th>\n",
       "      <th>x78</th>\n",
       "      <th>x79</th>\n",
       "      <th>x80</th>\n",
       "      <th>x81</th>\n",
       "      <th>x82</th>\n",
       "      <th>x83</th>\n",
       "      <th>x84</th>\n",
       "      <th>x85</th>\n",
       "      <th>x86</th>\n",
       "      <th>x87</th>\n",
       "      <th>x88</th>\n",
       "      <th>x89</th>\n",
       "      <th>x90</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>x100</th>\n",
       "      <th>x101</th>\n",
       "      <th>x102</th>\n",
       "      <th>x103</th>\n",
       "      <th>x104</th>\n",
       "      <th>x105</th>\n",
       "      <th>x106</th>\n",
       "      <th>x107</th>\n",
       "      <th>x108</th>\n",
       "      <th>x109</th>\n",
       "      <th>x110</th>\n",
       "      <th>x111</th>\n",
       "      <th>x112</th>\n",
       "      <th>x113</th>\n",
       "      <th>x114</th>\n",
       "      <th>x115</th>\n",
       "      <th>x116</th>\n",
       "      <th>x117</th>\n",
       "      <th>x118</th>\n",
       "      <th>x119</th>\n",
       "      <th>x120</th>\n",
       "      <th>x121</th>\n",
       "      <th>x122</th>\n",
       "      <th>x123</th>\n",
       "      <th>x124</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>1.281</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.87454</td>\n",
       "      <td>1.2164</td>\n",
       "      <td>0.06094</td>\n",
       "      <td>0.18827</td>\n",
       "      <td>0.52510</td>\n",
       "      <td>0.018854</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>0.85822</td>\n",
       "      <td>2.00580</td>\n",
       "      <td>0.12546</td>\n",
       "      <td>6.9706</td>\n",
       "      <td>4.6512</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>2.1984</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.024978</td>\n",
       "      <td>0.027264</td>\n",
       "      <td>1.4173</td>\n",
       "      <td>9.5554</td>\n",
       "      <td>0.148720</td>\n",
       "      <td>0.66995</td>\n",
       "      <td>214.760</td>\n",
       "      <td>12.641</td>\n",
       "      <td>6.4607</td>\n",
       "      <td>0.043835</td>\n",
       "      <td>0.20459</td>\n",
       "      <td>0.35179</td>\n",
       "      <td>8.3161</td>\n",
       "      <td>0.28922</td>\n",
       "      <td>0.76606</td>\n",
       "      <td>2.5825</td>\n",
       "      <td>77.400</td>\n",
       "      <td>0.026722</td>\n",
       "      <td>1.63070</td>\n",
       "      <td>0.015016</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>9.6951</td>\n",
       "      <td>-0.73622</td>\n",
       "      <td>0.98559</td>\n",
       "      <td>0.180160</td>\n",
       "      <td>1.5006</td>\n",
       "      <td>0.026224</td>\n",
       "      <td>7.0513</td>\n",
       "      <td>1174.9</td>\n",
       "      <td>5.3399</td>\n",
       "      <td>0.85128</td>\n",
       "      <td>12.837</td>\n",
       "      <td>0.061737</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>209.87</td>\n",
       "      <td>-0.58255</td>\n",
       "      <td>0.47101</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22009</td>\n",
       "      <td>0.130760</td>\n",
       "      <td>0.149520</td>\n",
       "      <td>0.195180</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>1224.50</td>\n",
       "      <td>1.04220</td>\n",
       "      <td>4.8920</td>\n",
       "      <td>6.72910</td>\n",
       "      <td>0.53860</td>\n",
       "      <td>104.410</td>\n",
       "      <td>0.49844</td>\n",
       "      <td>2.32240</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.14653</td>\n",
       "      <td>1.0214</td>\n",
       "      <td>24.402</td>\n",
       "      <td>-47.071</td>\n",
       "      <td>129</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>-0.4623</td>\n",
       "      <td>391.0</td>\n",
       "      <td>2870000.0</td>\n",
       "      <td>8.990000e+09</td>\n",
       "      <td>31</td>\n",
       "      <td>3.140000e+10</td>\n",
       "      <td>9.980000e-09</td>\n",
       "      <td>25.75</td>\n",
       "      <td>0.19693</td>\n",
       "      <td>74.25</td>\n",
       "      <td>38.44</td>\n",
       "      <td>15.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.1241</td>\n",
       "      <td>15.381</td>\n",
       "      <td>3.2702</td>\n",
       "      <td>17.872</td>\n",
       "      <td>34.692</td>\n",
       "      <td>30.087</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7991.4</td>\n",
       "      <td>364.9500</td>\n",
       "      <td>15.8</td>\n",
       "      <td>61.476</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>85.437</td>\n",
       "      <td>27.07</td>\n",
       "      <td>26.102</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.060390</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.455970</td>\n",
       "      <td>1.270</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.82067</td>\n",
       "      <td>1.0049</td>\n",
       "      <td>-0.01408</td>\n",
       "      <td>0.18104</td>\n",
       "      <td>0.62288</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.035991</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.85152</td>\n",
       "      <td>-0.48644</td>\n",
       "      <td>0.17933</td>\n",
       "      <td>4.5764</td>\n",
       "      <td>3.7521</td>\n",
       "      <td>-0.014011</td>\n",
       "      <td>2.4575</td>\n",
       "      <td>0.027558</td>\n",
       "      <td>0.028804</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>1.1801</td>\n",
       "      <td>7.2952</td>\n",
       "      <td>0.056026</td>\n",
       "      <td>0.67048</td>\n",
       "      <td>38.242</td>\n",
       "      <td>12.877</td>\n",
       "      <td>5.5506</td>\n",
       "      <td>0.265480</td>\n",
       "      <td>0.15019</td>\n",
       "      <td>0.41763</td>\n",
       "      <td>9.5276</td>\n",
       "      <td>0.41561</td>\n",
       "      <td>0.81699</td>\n",
       "      <td>2.6033</td>\n",
       "      <td>95.947</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.83754</td>\n",
       "      <td>0.027425</td>\n",
       "      <td>0.045434</td>\n",
       "      <td>0.13774</td>\n",
       "      <td>5.6035</td>\n",
       "      <td>-0.64385</td>\n",
       "      <td>1.30190</td>\n",
       "      <td>0.046857</td>\n",
       "      <td>1.0095</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>4.6022</td>\n",
       "      <td>1062.5</td>\n",
       "      <td>3.7389</td>\n",
       "      <td>0.94397</td>\n",
       "      <td>12.881</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>0.056298</td>\n",
       "      <td>250.14</td>\n",
       "      <td>-0.47477</td>\n",
       "      <td>0.38599</td>\n",
       "      <td>0.36933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.042671</td>\n",
       "      <td>-0.051995</td>\n",
       "      <td>-0.063643</td>\n",
       "      <td>-0.042465</td>\n",
       "      <td>-252.83</td>\n",
       "      <td>-0.23795</td>\n",
       "      <td>-2.0869</td>\n",
       "      <td>-0.98939</td>\n",
       "      <td>-0.23212</td>\n",
       "      <td>-10.857</td>\n",
       "      <td>-0.18801</td>\n",
       "      <td>0.90531</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.40390</td>\n",
       "      <td>1.8484</td>\n",
       "      <td>25.588</td>\n",
       "      <td>88.667</td>\n",
       "      <td>229</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>3.5409</td>\n",
       "      <td>126.0</td>\n",
       "      <td>371000.0</td>\n",
       "      <td>5.410000e+08</td>\n",
       "      <td>27</td>\n",
       "      <td>7.240000e+08</td>\n",
       "      <td>5.320000e-08</td>\n",
       "      <td>26.78</td>\n",
       "      <td>0.22990</td>\n",
       "      <td>73.22</td>\n",
       "      <td>42.86</td>\n",
       "      <td>15.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.4166</td>\n",
       "      <td>7.105</td>\n",
       "      <td>14.3210</td>\n",
       "      <td>18.770</td>\n",
       "      <td>124.760</td>\n",
       "      <td>26.124</td>\n",
       "      <td>11.8</td>\n",
       "      <td>8322.8</td>\n",
       "      <td>0.1896</td>\n",
       "      <td>15.6</td>\n",
       "      <td>24.579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>107.090</td>\n",
       "      <td>31.31</td>\n",
       "      <td>30.194</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company  Time  Financial Distress     x1        x2       x3      x4  \\\n",
       "0        1     1            0.010636  1.281  0.022934  0.87454  1.2164   \n",
       "1        1     2           -0.455970  1.270  0.006454  0.82067  1.0049   \n",
       "\n",
       "        x5       x6       x7        x8        x9       x10      x11      x12  \\\n",
       "0  0.06094  0.18827  0.52510  0.018854  0.182790  0.006449  0.85822  2.00580   \n",
       "1 -0.01408  0.18104  0.62288  0.006423  0.035991  0.001795  0.85152 -0.48644   \n",
       "\n",
       "       x13     x14     x15       x16     x17       x18       x19       x20  \\\n",
       "0  0.12546  6.9706  4.6512  0.050100  2.1984  0.018265  0.024978  0.027264   \n",
       "1  0.17933  4.5764  3.7521 -0.014011  2.4575  0.027558  0.028804  0.041102   \n",
       "\n",
       "      x21     x22       x23      x24      x25     x26     x27       x28  \\\n",
       "0  1.4173  9.5554  0.148720  0.66995  214.760  12.641  6.4607  0.043835   \n",
       "1  1.1801  7.2952  0.056026  0.67048   38.242  12.877  5.5506  0.265480   \n",
       "\n",
       "       x29      x30     x31      x32      x33     x34     x35       x36  \\\n",
       "0  0.20459  0.35179  8.3161  0.28922  0.76606  2.5825  77.400  0.026722   \n",
       "1  0.15019  0.41763  9.5276  0.41561  0.81699  2.6033  95.947  0.007580   \n",
       "\n",
       "       x37       x38       x39      x40     x41      x42      x43       x44  \\\n",
       "0  1.63070  0.015016  0.005478  0.12730  9.6951 -0.73622  0.98559  0.180160   \n",
       "1  0.83754  0.027425  0.045434  0.13774  5.6035 -0.64385  1.30190  0.046857   \n",
       "\n",
       "      x45       x46     x47     x48     x49      x50     x51       x52  \\\n",
       "0  1.5006  0.026224  7.0513  1174.9  5.3399  0.85128  12.837  0.061737   \n",
       "1  1.0095  0.007864  4.6022  1062.5  3.7389  0.94397  12.881 -0.000565   \n",
       "\n",
       "        x53     x54      x55      x56      x57  x58  x59      x60       x61  \\\n",
       "0  0.180900  209.87 -0.58255  0.47101  0.10990  0.0  0.0  0.22009  0.130760   \n",
       "1  0.056298  250.14 -0.47477  0.38599  0.36933  0.0  0.0  0.00000 -0.042671   \n",
       "\n",
       "        x62       x63       x64      x65      x66     x67      x68      x69  \\\n",
       "0  0.149520  0.195180  0.107500  1224.50  1.04220  4.8920  6.72910  0.53860   \n",
       "1 -0.051995 -0.063643 -0.042465  -252.83 -0.23795 -2.0869 -0.98939 -0.23212   \n",
       "\n",
       "       x70      x71      x72    x73      x74     x75     x76     x77  x78  \\\n",
       "0  104.410  0.49844  2.32240  300.0  0.14653  1.0214  24.402 -47.071  129   \n",
       "1  -10.857 -0.18801  0.90531  100.0  0.40390  1.8484  25.588  88.667  229   \n",
       "\n",
       "      x79     x80    x81        x82           x83  x84           x85  \\\n",
       "0  1200.0 -0.4623  391.0  2870000.0  8.990000e+09   31  3.140000e+10   \n",
       "1  1964.0  3.5409  126.0   371000.0  5.410000e+08   27  7.240000e+08   \n",
       "\n",
       "            x86    x87      x88    x89    x90    x91  x92  x93    x94  x95  \\\n",
       "0  9.980000e-09  25.75  0.19693  74.25  38.44  15.93  0.0  0.0  74.25    1   \n",
       "1  5.320000e-08  26.78  0.22990  73.22  42.86  15.94  0.0  0.0  73.22    1   \n",
       "\n",
       "   x96  x97  x98  x99  x100  x101    x102    x103     x104    x105     x106  \\\n",
       "0    2    0    5    0     0   0.8  7.1241  15.381   3.2702  17.872   34.692   \n",
       "1    2    0    5    0     0   0.6  7.4166   7.105  14.3210  18.770  124.760   \n",
       "\n",
       "     x107  x108    x109      x110  x111    x112  x113  x114     x115   x116  \\\n",
       "0  30.087  12.8  7991.4  364.9500  15.8  61.476   4.0  36.0   85.437  27.07   \n",
       "1  26.124  11.8  8322.8    0.1896  15.6  24.579   0.0  36.0  107.090  31.31   \n",
       "\n",
       "     x117  x118  x119  x120  x121      x122  x123  x124  \n",
       "0  26.102  16.0  16.0   0.2    22  0.060390    30    49  \n",
       "1  30.194  17.0  16.0   0.4    22  0.010636    31    50  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there's no missing data in the set\n",
    "assert XX.isnull().sum().sum() == 0, \"NaN present\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 3535],\n",
       "       [   1,  135]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"prepare target feature\"\"\"\n",
    "\n",
    "y = np.array(XX['Financial Distress'].values.tolist())\n",
    "y = np.array([0 if i > -0.50 else 1 for i in y])\n",
    "\n",
    "# check result\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "display(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x92 , number of unique values (categories):  37\n",
      "x94 , number of unique values (categories):  37\n",
      "x96 , number of unique values (categories):  37\n",
      "x97 , number of unique values (categories):  37\n",
      "x118 , number of unique values (categories):  37\n"
     ]
    }
   ],
   "source": [
    "\"\"\"define numerical and categorical features\"\"\"\n",
    "\n",
    "num_features = list(XX.iloc[:, np.r_[0:94, 95, 97, 100:120, 121:123]].columns.values)\n",
    "cat_features = list(XX.iloc[:, np.r_[94, 96, 98, 99, 120]].columns.values)\n",
    "cat_indices = [94, 96, 98, 99, 120]\n",
    "\n",
    "# check results\n",
    "for feature in cat_features:\n",
    "    print(feature, \", number of unique values (categories): \", XX['x121'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 95,\n",
       " 97,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 121,\n",
       " 122]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"split data into train and test, define datatypes\"\"\"\n",
    "\n",
    "indices = np.arange(y.shape[0])\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(XX, y, indices, stratify=y, test_size=0.3,\n",
    "                                                                 random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"define column selector class\"\"\"\n",
    "\n",
    "## Select Columns\n",
    "class MultiColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"assemble pipeline (define function)\"\"\"\n",
    "\n",
    "def build_pipe(X_train, y_train, clf, sampler):\n",
    "    \"\"\"Build a pipeline for preprocessing (including oversampling)\n",
    "    and classification.\n",
    "    \n",
    "    ARGUMENTS:\n",
    "        X_train: training features (df or array)\n",
    "        y_train: training labels (df or array)\n",
    "        clf: classifier (sk-learn model object)\n",
    "        sampler: sampler (imblearn sampling class)\n",
    "        \n",
    "    RETURNS:\n",
    "        full_pipe: pipeline object\n",
    "    \"\"\"\n",
    "    \n",
    "    full_pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "\n",
    "        ('cat', Pipeline([\n",
    "            ('cat_select', MultiColumn(cat_features)),\n",
    "            ('ohe', OneHotEncoder()),\n",
    "        ])),\n",
    "\n",
    "        ('num', Pipeline([\n",
    "            ('num_select', MultiColumn(num_features)),\n",
    "            ('scaling', StandardScaler()),\n",
    "        ])),\n",
    "    ])),\n",
    "        ('sample', sampler),\n",
    "        ('clf', clf)])\n",
    "    \n",
    "    return full_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"initialize  classifier and SMOTENC sampler, build pipeline\"\"\" \n",
    "\n",
    "rg = LogisticRegression(class_weight = { 0:1, 1:8 }, random_state = 42, solver = 'saga',\n",
    "                        max_iter=100, n_jobs=-1, intercept_scaling=1, C=0.02, penalty='l1')\n",
    "\n",
    "sampler = SMOTENC(categorical_features=cat_indices, n_jobs=-1)\n",
    "\n",
    "full_pipe = build_pipe(X_train, y_train, rg, sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pipe(X_train, y_train, pipe, scorer, cv=StratifiedKFold(3)):\n",
    "    \"\"\"Fit training data to a pipeline with GridSearchCV\n",
    "    for best parameter tuning.\n",
    "    \n",
    "    ARGUMENTS:\n",
    "        X_train: training features (df or array)\n",
    "        y_train: training labels (df or array)\n",
    "        pipe: pipeline (sk-learn pipeline object)\n",
    "        scorer: evaluation metric for validation\n",
    "        cv: type of CV, default is StratifiedKFold(3)\n",
    "        \n",
    "    RETURNS:\n",
    "        grid: grid search object\n",
    "        grid_results: dict with grid search results\n",
    "    \"\"\"\n",
    "    parameters = {'clf__C': [0.001, 0.01, 0.025], \n",
    "                  'clf__class_weight':   [{ 0:1, 1:11 }, { 0:1, 1:8 }]}\n",
    "\n",
    "    cv = GridSearchCV(pipe, param_grid=parameters, scoring=scorer, n_jobs= -1, \n",
    "                      cv=cv, error_score='raise', return_train_score=False, verbose=1)\n",
    "\n",
    "    grid = cv.fit(X_train, y_train) \n",
    "    grid_results = grid.cv_results_\n",
    "\n",
    "    return grid, grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   25.8s finished\n",
      "C:\\Users\\r2d4\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\r2d4\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\r2d4\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\r2d4\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# call the function and evaluate on fbeta score\n",
    "\n",
    "scorer = make_scorer(fbeta_score, beta=4)\n",
    "cv = 3\n",
    "\n",
    "grid, grid_results = fit_pipe(X_train, y_train, full_pipe, scorer, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- i have renamed cat_indices to cat_features - indices is for naming rows only\n",
    "- i have integrated the SMOTENC sampler into the pipeline, to make sure the oversampling is at the end because oversampling transforms your dataframe into an np.array and you lose all your feature labels / column names that probably caused the problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
